{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "KBcOZFUfhvnK"
   },
   "outputs": [],
   "source": [
    "# –î–∞—Ç–∞—Å–µ—Ç\n",
    "BOT_CONFIG = {\"intents\": {\"normocontrol\": {\"examples\": [\"–ß—Ç–æ —ç—Ç–æ –Ω–æ—Ä–º–æ–∫–æ–Ω—Ç—Ä–æ–ª—å?\", \"–ß—Ç–æ –µ—Å—Ç—å —Ç–∞–∫–æ–µ –Ω–æ—Ä–º–æ–∫–æ–Ω—Ç—Ä–æ–ª—å?\", \"–ß—Ç–æ —Ç–∞–∫–æ–µ –Ω–æ—Ä–º–æ–∫–æ–Ω—Ç—Ä–æ–ª—å?\", \"–ö–∞–∫ –ø—Ä–æ—Ö–æ–¥–∏—Ç –Ω–æ—Ä–º–æ–∫–æ–Ω—Ç—Ä–æ–ª—å?\", \"–ß—Ç–æ –∏–∑ —Å–µ–±—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ—Ä–º–æ–∫–æ–Ω—Ç—Ä–æ–ª—å?\", \"–ß—Ç–æ –Ω—É–∂–Ω–æ –¥–ª—è –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏—è –Ω–æ—Ä–º–∫–æ–Ω—Ç—Ä–æ–ª—è?\", \"–ß—Ç–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –¥–ª—è –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏—è –Ω–æ—Ä–º–∫–æ–Ω—Ç—Ä–æ–ª—è?\", \"–ß—Ç–æ —Ç—Ä–µ–±—É–µ—Ç—Å—è –¥–ª—è –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏—è –Ω–æ—Ä–º–∫–æ–Ω—Ç—Ä–æ–ª—è?\", \"–î–ª—è —á–µ–≥–æ –Ω—É–∂–µ–Ω –Ω–æ—Ä–º–æ–∫–æ–Ω—Ç—Ä–æ–ª—å?\", \"–ö–∞–∫ –ø—Ä–æ–π—Ç–∏ –Ω–æ—Ä–º–æ–∫–æ–Ω—Ç—Ä–æ–ª—å?\", \"–ß—Ç–æ –≤–∫–ª—é—á–∞–µ—Ç –≤ —Å–µ–±—è –Ω–æ—Ä–º–æ–∫–æ–Ω—Ç—Ä–æ–ª—å?\", \"–ß—Ç–æ –≤—Ö–æ–¥–∏—Ç –≤ –Ω–æ—Ä–º–æ–∫–æ–Ω—Ç—Ä–æ–ª—å?\", \"–ö–∞–∫ –±—É–¥–µ—Ç –ø—Ä–æ—Ö–æ–¥–∏—Ç—å –Ω–æ—Ä–º–æ–∫–æ–Ω—Ç—Ä–æ–ª—å?\", \"–ß—Ç–æ –±—É–¥–µ—Ç –≤—Ö–æ–¥–∏—Ç—å –≤ –Ω–æ—Ä–º–æ–∫–æ–Ω—Ç—Ä–æ–ª—å?\", \"–ß—Ç–æ –±—É–¥–µ—Ç –≤–∫–ª—é—á–µ–Ω–æ –≤ –Ω–æ—Ä–º–æ–∫–æ–Ω—Ç—Ä–æ–ª—å?\", \"–ß—Ç–æ –ø–æ—Ç—Ä–µ–±—É–µ—Ç—Å—è –¥–ª—è –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏—è –Ω–æ—Ä–º–∫–æ–Ω—Ç—Ä–æ–ª—è?\", \"–ß—Ç–æ –∏–∑ —Å–µ–±—è –±—É–¥–µ—Ç –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—Ç—å –Ω–æ—Ä–º–æ–∫–æ–Ω—Ç—Ä–æ–ª—å?\", \"–ß—Ç–æ –±—É–¥–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –¥–ª—è –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏—è –Ω–æ—Ä–º–∫–æ–Ω—Ç—Ä–æ–ª—è?\", \"–ß—Ç–æ –±—É–¥–µ—Ç –Ω—É–∂–Ω–æ –¥–ª—è –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏—è –Ω–æ—Ä–º–∫–æ–Ω—Ç—Ä–æ–ª—è?\", \"–ß—Ç–æ –±—É–¥–µ—Ç –≤–∫–ª—é—á–∞—Ç—å –≤ —Å–µ–±—è –Ω–æ—Ä–º–æ–∫–æ–Ω—Ç—Ä–æ–ª—å?\", \"–°–∫–∏–Ω—å –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –¥–ª—è –Ω–æ—Ä–º–∫–æ–Ω—Ç—Ä–æ–ª—è\", \"–°–∫–∏–Ω—å –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –¥–ª—è –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏—è –Ω–æ—Ä–º–∫–æ–Ω—Ç—Ä–æ–ª—è\", \"–°–∫–∏–Ω—å –Ω–æ—Ä–º–∞—Ç–∏–≤—ã –¥–ª—è –Ω–æ—Ä–º–∫–æ–Ω—Ç—Ä–æ–ª—è\", \"–ì–¥–µ –Ω–∞–π—Ç–∏ –Ω–æ—Ä–º–∞—Ç–∏–≤—ã –¥–ª—è –Ω–æ—Ä–º–∫–æ–Ω—Ç—Ä–æ–ª—è?\", \"–ì–¥–µ –Ω–∞–π—Ç–∏ –Ω–æ—Ä–º–∞—Ç–∏–≤—ã –¥–ª—è –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏—è –Ω–æ—Ä–º–∫–æ–Ω—Ç—Ä–æ–ª—è?\", \"–ì–¥–µ –Ω–∞–π—Ç–∏ –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –¥–ª—è –Ω–æ—Ä–º–∫–æ–Ω—Ç—Ä–æ–ª—è?\", \"–ì–¥–µ –Ω–∞–π—Ç–∏ –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –¥–ª—è –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏—è –Ω–æ—Ä–º–∫–æ–Ω—Ç—Ä–æ–ª—è?\", \"–í—ã—à–ª–∏ –Ω–æ—Ä–º–∞—Ç–∏–≤—ã –¥–ª—è –Ω–æ—Ä–º–∫–æ–Ω—Ç—Ä–æ–ª—è\", \"–í—ã—à–ª–∏ –Ω–æ—Ä–º–∞—Ç–∏–≤—ã –¥–ª—è –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏—è –Ω–æ—Ä–º–∫–æ–Ω—Ç—Ä–æ–ª—è\", \"–í—ã—à–ª–∏ –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –¥–ª—è –Ω–æ—Ä–º–∫–æ–Ω—Ç—Ä–æ–ª—è\", \"–í—ã—à–ª–∏ –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –¥–ª—è –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏—è –Ω–æ—Ä–º–∫–æ–Ω—Ç—Ä–æ–ª—è\"], \"responses\": [\"üìå–ù–æ—Ä–º–æ–∫–æ–Ω—Ç—Ä–æ–ª—å ‚Äì —ç—Ç–æ –ø—Ä–æ–≤–µ—Ä–∫–∞ –≤—ã–ø—É—Å–∫–Ω–æ–π –∫–≤–∞–ª–∏—Ñ–∏–∫–∞—Ü–∏–æ–Ω–Ω–æ–π —Ä–∞–±–æ—Ç—ã –Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º, –∞ —Ç–∞–∫–∂–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —É—á–µ–±–Ω–æ–≥–æ –∑–∞–≤–µ–¥–µ–Ω–∏—è.\", \"\\t\\t–¶–µ–ª—å—é —Ç–∞–∫–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ —è–≤–ª—è–µ—Ç—Å—è –ø–æ–º–æ—â—å —Å—Ç—É–¥–µ–Ω—Ç—É –Ω–∞–ø–∏—Å–∞—Ç—å –∏ –æ—Ñ–æ—Ä–º–∏—Ç—å —Ä–∞–±–æ—Ç—É, —á—Ç–æ–±—ã –Ω–∞ –∑–∞—â–∏—Ç–µ –¥–∏–ø–ª–æ–º–Ω–æ–π —Ä–∞–±–æ—Ç—ã –Ω–µ –≤–æ–∑–Ω–∏–∫–∞–ª–æ –Ω–∏–∫–∞–∫–∏—Ö –≤–æ–ø—Ä–æ—Å–æ–≤ –ø–æ –ø–æ–≤–æ–¥—É –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—è.\\t\\t–ù–æ—Ä–º–æ–∫–æ–Ω—Ç—Ä–æ–ª—å ‚Äì —ç—Ç–æ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π —ç—Ç–∞–ø –Ω–∞–ø–∏—Å–∞–Ω–∏—è –≤—ã–ø—É—Å–∫–Ω—ã—Ö —Ä–∞–±–æ—Ç –≤ –≤—ã—Å—à–∏—Ö —É—á–µ–±–Ω—ã—Ö –∑–∞–≤–µ–¥–µ–Ω–∏—è—Ö.\", \"  –ù–∞ –Ω–æ—Ä–º–æ–∫–æ–Ω—Ç—Ä–æ–ª—å –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –∏–º–µ—Ç—å –ø—Ä–∏ —Å–µ–±–µ:\", \" ‚Ä¢ –ø–æ—è—Å–Ω–∏—Ç–µ–ª—å–Ω—É—é –∑–∞–ø–∏—Å–∫—É;\", \" ‚Ä¢ 2 –∫–æ–º–ø–∞–∫—Ç-–¥–∏—Å–∫–∞ (+–¥–≤–µ —ç—Ç–∏–∫–µ—Ç–∫–∏, –ø–æ–¥–ø–∏—Å–∞–Ω–Ω—ã–µ —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª–µ–º);\", \" ‚Ä¢ –≥—Ä–∞—Ñ–∏—á–µ—Å–∫—É—é —á–∞—Å—Ç—å;\", \" ‚Ä¢ –æ—Ç–∑—ã–≤ —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—è;\", \" ‚Ä¢ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–∞ –∞–Ω—Ç–∏–ø–ª–∞–≥–∏–∞—Ç;\", \" ‚Ä¢ —Ä–∞–∑–¥–∞—Ç–æ—á–Ω—ã–π –º–∞—Ç–µ—Ä–∏–∞–ª (5 –∫–æ–ø–∏–π –≥—Ä–∞—Ñ–∏—á–µ—Å–∫–æ–π —á–∞—Å—Ç–∏);\", \" ‚Ä¢ –∞–∫—Ç –æ –≤–Ω–µ–¥—Ä–µ–Ω–∏–∏ (–ø—Ä–∏ –Ω–∞–ª–∏—á–∏–∏);\", \" ‚Ä¢ —Ä–µ—Ü–µ–Ω–∑–∏—è (–¥–ª—è –º–∞–≥–∏—Å—Ç—Ä–∞–Ω—Ç–æ–≤).\"]}, \"title\": {\"examples\": [\"–ö–∞–∫ –æ—Ñ–æ—Ä–º–∏—Ç—å —Ç–∏—Ç—É–ª—å–Ω–∏–∫?\", \"–ö–∞–∫ –æ—Ñ–æ—Ä–º–∏—Ç—å —Ç–∏—Ç—É–ª—å–Ω—ã–π –ª–∏—Å—Ç?\", \"–ö–∞–∫–æ–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—è —Ç–∏—Ç—É–ª—å–Ω–æ–≥–æ –ª–∏—Å—Ç–∞?\", \"–ö–∞–∫–æ–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—è —Ç–∏—Ç—É–ª—å–Ω–∏–∫–∞?\", \"–ß—å–∏ –ø–æ–¥–ø–∏—Å–∏ –Ω—É–∂–Ω—ã –Ω–∞ —Ç–∏—Ç—É–ª—å–Ω–æ–º –ª–∏—Å—Ç–µ?\", \"–ß—å–∏ –ø–æ–¥–ø–∏—Å–∏ –Ω—É–∂–Ω—ã –Ω–∞ —Ç–∏—Ç—É–ª—å–Ω–∏–∫–µ?\", \"–ö—Ç–æ –¥–æ–ª–∂–µ–Ω —Ä–∞—Å–ø–∏—Å–∞—Ç—å—Å—è –Ω–∞ —Ç–∏—Ç—É–ª—å–Ω–æ–º –ª–∏—Å—Ç–µ?\", \"–ö—Ç–æ –¥–æ–ª–∂–µ–Ω —Ä–∞—Å–ø–∏—Å–∞—Ç—å—Å—è –Ω–∞ —Ç–∏—Ç—É–ª—å–Ω–∏–∫–µ?\", \"–ö–∞–∫ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –æ—Ñ–æ—Ä–º–ª–µ–Ω —Ç–∏—Ç—É–ª—å–Ω—ã–π –ª–∏—Å—Ç?\", \"–ö–∞–∫ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –æ—Ñ–æ—Ä–º–ª–µ–Ω —Ç–∏—Ç—É–ª—å–Ω–∏–∫?\", \"–ö–∞–∫ –∑–∞–ø–æ–ª–Ω–∏—Ç—å —Ç–∏—Ç—É–ª—å–Ω—ã–π –ª–∏—Å—Ç?\", \"–ö–∞–∫ –∑–∞–ø–æ–ª–Ω–∏—Ç—å —Ç–∏—Ç—É–ª—å–Ω–∏–∫?\", \"–ö–∞–∫ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∑–∞–ø–æ–ª–Ω–µ–Ω —Ç–∏—Ç—É–ª—å–Ω—ã–π –ª–∏—Å—Ç?\", \"–ö–∞–∫ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∑–∞–ø–æ–ª–Ω–µ–Ω —Ç–∏—Ç—É–ª—å–Ω–∏–∫?\"], \"responses\": [\"üßæ–¢–∏—Ç—É–ª—å–Ω—ã–π –ª–∏—Å—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∑–∞–ø–æ–ª–Ω–µ–Ω –∏ –ø–æ–¥–ø–∏—Å–∞–Ω:\", \"- —Å—Ç—É–¥–µ–Ω—Ç–æ–º –∏ —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª–µ–º (–¥–ª—è –±–∞–∫–∞–ª–∞–≤—Ä–æ–≤);\", \"- —Å—Ç—É–¥–µ–Ω—Ç–æ–º, —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª–µ–º –∏ —Ä–µ—Ü–µ–Ω–∑–µ–Ω—Ç–æ–º (–¥–ª—è –º–∞–≥–∏—Å—Ç—Ä–∞–Ω—Ç–æ–≤).\"]}, \"task\": {\"examples\": [\"–ö–∞–∫ –æ—Ñ–æ—Ä–º–∏—Ç—å –∑–∞–¥–∞–Ω–∏–µ –∫ –í–ö–†?\", \"–ö–∞–∫ –æ—Ñ–æ—Ä–º–∏—Ç—å –∑–∞–¥–∞–Ω–∏–µ –∫ –¥–∏–ø–ª–æ–º—É?\", \"–ö–∞–∫ –æ—Ñ–æ—Ä–º–∏—Ç—å –¥–∏–ø–ª–æ–º–Ω–æ–µ –∑–∞–¥–∞–Ω–∏–µ?\", \"–ö–∞–∫–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—é –∑–∞–¥–∞–Ω–∏—è –∫ –í–ö–†?\", \"–ö–∞–∫–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—é –∑–∞–¥–∞–Ω–∏—è –ø–æ –¥–∏–ø–ª–æ–º—É?\", \"–ö–∞–∫–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—é –¥–∏–ø–ª–æ–º–Ω–æ–≥–æ –∑–∞–¥–∞–Ω–∏—è?\", \"–ö–∞–∫–æ–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—è –∑–∞–¥–∞–Ω–∏—è –∫ –í–ö–†?\", \"–ö–∞–∫–æ–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—è –¥–∏–ø–ª–æ–º–Ω–æ–≥–æ –∑–∞–¥–∞–Ω–∏—è?\", \"–ö–∞–∫–æ–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—è –∑–∞–¥–∞–Ω–∏—è –ø–æ –¥–∏–ø–ª–æ–º—É?\", \"–ö–∞–∫ –∑–∞–ø–æ–ª–Ω–∏—Ç—å –∑–∞–¥–∞–Ω–∏–µ –∫ –í–ö–†?\", \"–ö–∞–∫ –∑–∞–ø–æ–ª–Ω–∏—Ç—å –∑–∞–¥–∞–Ω–∏–µ –∫ –¥–∏–ø–ª–æ–º—É?\", \"–ö–∞–∫ –∑–∞–ø–æ–ª–Ω–∏—Ç—å –¥–∏–ø–ª–æ–º–Ω–æ–µ –∑–∞–¥–∞–Ω–∏–µ?\", \"–ö–∞–∫ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –∑–∞–ø–æ–ª–Ω–µ–Ω–æ –∑–∞–¥–∞–Ω–∏–µ –∫ –í–ö–†?\", \"–ö–∞–∫ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –∑–∞–ø–æ–ª–Ω–µ–Ω–æ –∑–∞–¥–∞–Ω–∏–µ –∫ –¥–∏–ø–ª–æ–º—É?\", \"–ö–∞–∫ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –∑–∞–ø–æ–ª–Ω–µ–Ω–æ –¥–∏–ø–ª–æ–º–Ω–æ–µ –∑–∞–¥–∞–Ω–∏–µ?\", \"–ß—å–∏ –ø–æ–¥–ø–∏—Å–∏ –Ω—É–∂–Ω—ã –Ω–∞ –∑–∞–¥–∞–Ω–∏–∏ –∫ –í–ö–†?\", \"–ß—å–∏ –ø–æ–¥–ø–∏—Å–∏ –Ω—É–∂–Ω—ã –Ω–∞ –∑–∞–¥–∞–Ω–∏–∏ –∫ –¥–∏–ø–ª–æ–º—É?\", \"–ß—å–∏ –ø–æ–¥–ø–∏—Å–∏ –Ω—É–∂–Ω—ã –Ω–∞ –¥–∏–ø–ª–æ–º–Ω–æ–º –∑–∞–¥–∞–Ω–∏–∏?\", \"–ö—Ç–æ –¥–æ–ª–∂–µ–Ω —Ä–∞—Å–ø–∏—Å–∞—Ç—å—Å—è –Ω–∞ –∑–∞–¥–∞–Ω–∏–∏ –∫ –í–ö–†?\", \"–ö—Ç–æ –¥–æ–ª–∂–µ–Ω —Ä–∞—Å–ø–∏—Å–∞—Ç—å—Å—è –Ω–∞ –∑–∞–¥–∞–Ω–∏–∏ –∫ –¥–∏–ø–ª–æ–º—É?\", \"–ö—Ç–æ –¥–æ–ª–∂–µ–Ω —Ä–∞—Å–ø–∏—Å–∞—Ç—å—Å—è –Ω–∞ –¥–∏–ø–ª–æ–º–Ω–æ–º –∑–∞–¥–∞–Ω–∏–∏?\"], \"responses\": [\"üìù–ó–∞–¥–∞–Ω–∏–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –∑–∞–ø–æ–ª–Ω–µ–Ω–æ, —Ä–∞—Å–ø–µ—á–∞—Ç–∞–Ω–æ –Ω–∞ –æ–¥–Ω–æ–º –ª–∏—Å—Ç–µ (—Å –¥–≤—É—Ö —Å—Ç–æ—Ä–æ–Ω) –∏ –ø–æ–¥–ø–∏—Å–∞–Ω–æ —Å—Ç—É–¥–µ–Ω—Ç–æ–º –∏ —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª–µ–º.\"]}, \"annotation\": {\"examples\": [\"–ö–∞–∫ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –æ—Ñ–æ—Ä–º–ª–µ–Ω–∞ –∞–Ω–Ω–æ—Ç–∞—Ü–∏—è?\", \"–ö–∞–∫ –∑–∞–ø–æ–ª–Ω–∏—Ç—å –∞–Ω–Ω–æ—Ç–∞—Ü–∏—é?\", \"–ö–∞–∫–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏?\", \"–ö–∞–∫–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—é –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏?\", \"–ö–∞–∫ –æ—Ñ–æ—Ä–º–∏—Ç—å –∞–Ω–Ω–æ—Ç–∞—Ü–∏—é?\", \"–ö–∞–∫ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –æ—Ñ–æ—Ä–º–∏—Ç—å –∞–Ω–Ω–æ—Ç–∞—Ü–∏—é?\", \"–ö—Ç–æ –¥–æ–ª–∂–µ–Ω —Ä–∞—Å–ø–∏—Å–∞—Ç—å—Å—è –Ω–∞ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏?\", \"–ß—å–∏ –ø–æ–¥–ø–∏—Å–∏ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –Ω–∞ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏?\", \"–ö–∞–∫–æ–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏?\"], \"responses\": [\"üìÑ–ê–Ω–Ω–æ—Ç–∞—Ü–∏—è –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –∑–∞–ø–æ–ª–Ω–µ–Ω–∞, —Ä–∞—Å–ø–µ—á–∞—Ç–∞–Ω–∞ –Ω–∞ –æ–¥–Ω–æ–º –ª–∏—Å—Ç–µ (—Å –¥–≤—É—Ö —Å—Ç–æ—Ä–æ–Ω) –∏ –ø–æ–¥–ø–∏—Å–∞–Ω–∞ —Å—Ç—É–¥–µ–Ω—Ç–æ–º.\"]}, \"content\": {\"examples\": [\"–ö–∞–∫ –æ—Ñ–æ—Ä–º–∏—Ç—å —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ?\", \"–ö–∞–∫ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –æ—Ñ–æ—Ä–º–ª–µ–Ω–æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ?\", \"–ö–∞–∫ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –æ—Ñ–æ—Ä–º–∏—Ç—å —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ?\", \"–ö–∞–∫ –∑–∞–ø–æ–ª–Ω–∏—Ç—å —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ?\", \"–ö–∞–∫–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—é —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è?\", \"–ö—Ç–æ –¥–æ–ª–∂–µ–Ω –ø–æ–¥–ø–∏—Å–∞—Ç—å —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ?\", \"–ß—å–∏ –ø–æ–¥–ø–∏—Å–∏ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –≤ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–∏?\", \"–ö–∞–∫–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—é?\"], \"responses\": [\"üìÑ–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –ø–æ–¥–ø–∏—Å–∞–Ω–æ:\", \"- —Å—Ç—É–¥–µ–Ω—Ç–æ–º –∏ —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª–µ–º (–¥–ª—è –±–∞–∫–∞–ª–∞–≤—Ä–æ–≤);\", \"- —Å—Ç—É–¥–µ–Ω—Ç–æ–º, —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª–µ–º –∏ —Ä–µ—Ü–µ–Ω–∑–µ–Ω—Ç–æ–º (–¥–ª—è –º–∞–≥–∏—Å—Ç—Ä–∞–Ω—Ç–æ–≤).\", \"–û–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ, —á—Ç–æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –≤—Å–µ–≥–¥–∞ —Ä–∞—Å–ø–æ–ª–∞–≥–∞–µ—Ç—Å—è –Ω–∞ 4-–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ (–≤ —Ä–∞–º–∫–µ, –≤ –≥—Ä–∞—Ñ–µ ¬´–ª–∏—Å—Ç¬ª –¥–æ–ª–∂–Ω–∞ —Å—Ç–æ—è—Ç—å —Ü–∏—Ñ—Ä–∞ 4).\"]}, \"work\": {\"examples\": [\"–ö–∞–∫–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –ø–æ—è—Å–Ω–∏—Ç–µ–ª—å–Ω–æ–π –∑–∞–ø–∏—Å–∫–∏?\", \"–ö–∞–∫–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –ü–ó?\", \"–ö–∞–∫ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –æ—Ñ–æ—Ä–º–ª–µ–Ω–∞ –ø–æ—è—Å–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∑–∞–ø–∏—Å–∫–∞?\", \"–ö–∞–∫ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –æ—Ñ–æ—Ä–º–ª–µ–Ω–∞ –ü–ó?\", \"–ö–∞–∫ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –æ—Ñ–æ—Ä–º–∏—Ç—å –ø–æ—è—Å–Ω–∏—Ç–µ–ª—å–Ω—É—é –∑–∞–ø–∏—Å–∫—É?\", \"–ö–∞–∫ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –æ—Ñ–æ—Ä–º–∏—Ç—å –ü–ó?\", \"–ö–∞–∫ –æ—Ñ–æ—Ä–º–∏—Ç—å –ø–æ—è—Å–Ω–∏—Ç–µ–ª—å–Ω—É—é –∑–∞–ø–∏—Å–∫—É?\", \"–ö–∞–∫ –æ—Ñ–æ—Ä–º–∏—Ç—å –ü–ó?\", \"–ö–∞–∫–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—é –ø–æ—è—Å–Ω–∏—Ç–µ–ª—å–Ω–æ–π –∑–∞–ø–∏—Å–∫–∏?\", \"–ö–∞–∫–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—é –ü–ó?\", \"–ö–∞–∫ –∑–∞–ø–æ–ª–Ω–∏—Ç—å –ø–æ—è—Å–Ω–∏—Ç–µ–ª—å–Ω—É—é –∑–∞–ø–∏—Å–∫—É?\", \"–ö–∞–∫ –∑–∞–ø–æ–ª–Ω–∏—Ç—å –ü–ó?\"], \"responses\": [\"üìÑ–†–∞–±–æ—Ç–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –æ—Ñ–æ—Ä–º–ª–µ–Ω–∞ –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Å–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–æ–º.\"]}, \"literature\": {\"examples\": [\"–ö–∞–∫ –∑–∞–ø–æ–ª–Ω–∏—Ç—å —Å–ø–∏—Å–æ–∫ –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä—ã?\", \"–ö–∞–∫ –Ω—É–∂–Ω–æ –æ—Ñ–æ—Ä–º–∏—Ç—å —Å–ø–∏—Å–æ–∫ –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä—ã?\", \"–ö–∞–∫ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –æ—Ñ–æ—Ä–º–∏—Ç—å —Å–ø–∏—Å–æ–∫ –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä—ã?\", \"–ö–∞–∫ –æ—Ñ–æ—Ä–º–∏—Ç—å —Å–ø–∏—Å–æ–∫ –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä—ã?\", \"–ö–∞–∫–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ —Å–ø–∏—Å–∫—É –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä—ã?\", \"–ö–∞–∫–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—é —Å–ø–∏—Å–∫–∞ –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä—ã?\", \"–ö–∞–∫ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –æ—Ñ–æ—Ä–º–ª–µ–Ω —Å–ø–∏—Å–æ–∫ –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä—ã? \"], \"responses\": [\"üìÑ–°–ø–∏—Å–æ–∫ –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä—ã –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –æ—Ñ–æ—Ä–º–ª–µ–Ω –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Å –ì–û–°–¢‚Äô–æ–º.\"]}, \"supplement\": {\"examples\": [\"–ö–∞–∫ –Ω—É–∂–Ω–æ –æ—Ñ–æ—Ä–º–∏—Ç—å –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ?\", \"–ö–∞–∫ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –æ—Ñ–æ—Ä–º–∏—Ç—å –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ?\", \"–ö–∞–∫ –æ—Ñ–æ—Ä–º–∏—Ç—å –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ?\", \"–ö–∞–∫–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—é –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è?\", \"–ö–∞–∫–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—é?\", \"–ö–∞–∫ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –æ—Ñ–æ—Ä–º–ª–µ–Ω –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ? \", \"–ö–∞–∫ –∑–∞–ø–æ–ª–Ω–∏—Ç—å –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ?\"], \"responses\": [\"üìÑ–ü—Ä–∏–ª–æ–∂–µ–Ω–∏—è —Ä–∞—Å–ø–µ—á–∞—Ç—ã–≤–∞—é—Ç—Å—è –±–µ–∑ —Ä–∞–º–∫–∏, –Ω–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –Ω—É–º–µ—Ä—É—é—Ç—Å—è –∏ –ø—Ä–∏ –ø–æ–¥—Å—á–µ—Ç–µ –æ–±—ä–µ–º–∞ (–∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å—Ç—Ä–∞–Ω–∏—Ü) –í–ö–† —É—á–∏—Ç—ã–≤–∞—é—Ç—Å—è.\"]}, \"after\": {\"examples\": [\"–ß—Ç–æ –¥–µ–ª–∞—Ç—å –ø–æ—Å–ª–µ –Ω–æ—Ä–º–∫–æ–Ω—Ç—Ä–æ–ª—è?\", \"–ß—Ç–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —Å–¥–µ–ª–∞—Ç—å –ø–æ—Å–ª–µ –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏—è –Ω–æ—Ä–º–∫–æ–Ω—Ç—Ä–æ–ª—è?\", \"–ß—Ç–æ –Ω—É–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å –ø–æ—Å–ª–µ –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏—è –Ω–æ—Ä–º–∫–æ–Ω—Ç—Ä–æ–ª—è?\", \"–ß—Ç–æ –¥–µ–ª–∞—Ç—å –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–≥–æ –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏—è –Ω–æ—Ä–º–∫–æ–Ω—Ç—Ä–æ–ª—è?\", \"–ß—Ç–æ –¥–µ–ª–∞—Ç—å –ø–æ—Å–ª–µ –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏—è –Ω–æ—Ä–º–∫–æ–Ω—Ç—Ä–æ–ª—è?\"], \"responses\": [\"‚Äº–ü–æ—Å–ª–µ –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏—è –Ω–æ—Ä–º–æ–∫–æ–Ω—Ç—Ä–æ–ª—è –ø–æ—è—Å–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∑–∞–ø–∏—Å–∫–∞ –ø—Ä–æ—à–∏–≤–∞–µ—Ç—Å—è (–Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –±—É–¥–µ—Ç —Å–¥–µ–ª–∞—Ç—å —Ç–≤–µ—Ä–¥—ã–π –ø–µ—Ä–µ–ø–ª–µ—Ç).\", \"\\t\\t–ü—Ä–∏—á–µ–º, –ø—Ä–æ—à–∏–≤–∞–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –ü–ó! –ì—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–π –º–∞—Ç–µ—Ä–∏–∞–ª (–ø–æ–¥–ø–∏—Å–∞–Ω–Ω—ã–µ –ª–∏—Å—Ç—ã) –ø—Ä–∏–∫–ª–∞–¥—ã–≤–∞—é—Ç—Å—è –≤ —Ñ–∞–π–ª–∏–∫–µ –æ—Ç–¥–µ–ª—å–Ω–æ, –æ—Ç–∑—ã–≤ —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—è - –æ—Ç–¥–µ–ª—å–Ω–æ, –∞–Ω—Ç–∏–ø–ª–∞–≥–∏–∞—Ç - –æ—Ç–¥–µ–ª—å–Ω–æ\"]}, \"CD-ROM\": {\"examples\": [\"–ö—Ç–æ –ø–æ–¥–ø–∏—Å—ã–≤–∞–µ—Ç –¥–∏—Å–∫–∏?\", \"–ö–∞–∫ –ø–æ–¥–ø–∏—Å–∞—Ç—å –∫–æ–º–ø–∞–∫—Ç-–¥–∏—Å–∫–∏?\", \"–°–∫–æ–ª—å–∫–æ –¥–∏—Å–∫–æ–≤ –Ω—É–∂–Ω–æ?\", \"–°–∫–æ–ª—å–∫–æ –∫–æ–º–ø–∞–∫—Ç-–¥–∏—Å–∫–æ–≤ –Ω—É–∂–Ω–æ?\", \"–ö—Ç–æ –¥–æ–ª–∂–µ–Ω –ø–æ–¥–ø–∏—Å–∞—Ç—å –¥–∏—Å–∫–∏?\", \"–ö—Ç–æ –¥–æ–ª–∂–µ–Ω –ø–æ–¥–ø–∏—Å–∞—Ç—å –∫–æ–º–ø–∞–∫—Ç-–¥–∏—Å–∫–∏?\", \"–ß—å–∏ –ø–æ–¥–ø–∏—Å–∏ –Ω—É–∂–Ω—ã –Ω–∞ –¥–∏—Å–∫–∞—Ö?\", \"–ß—å–∏ –ø–æ–¥–ø–∏—Å–∏ –Ω—É–∂–Ω—ã –Ω–∞ –∫–æ–º–ø–∞–∫—Ç-–¥–∏—Å–∫–∞—Ö?\", \"–ß—Ç–æ –∑–∞–ø–∏—Å—ã–≤–∞—Ç—å –Ω–∞ –ø–µ—Ä–≤—ã–π –¥–∏—Å–∫?\", \"–ß—Ç–æ –∑–∞–ø–∏—Å—ã–≤–∞—Ç—å –Ω–∞ –ø–µ—Ä–≤—ã–π –∫–æ–º–ø–∞–∫—Ç-–¥–∏—Å–∫?\", \"–ß—Ç–æ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –Ω–∞ –ø–µ—Ä–≤–æ–º –¥–∏—Å–∫–µ?\", \"–ß—Ç–æ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –Ω–∞ –ø–µ—Ä–≤–æ–º –∫–æ–º–ø–∞–∫—Ç-–¥–∏—Å–∫–µ?\", \"–ß—Ç–æ –∑–∞–ø–∏—Å—ã–≤–∞—Ç—å –Ω–∞ –≤—Ç–æ—Ä–æ–π –¥–∏—Å–∫?\", \"–ß—Ç–æ –∑–∞–ø–∏—Å—ã–≤–∞—Ç—å –Ω–∞ –≤—Ç–æ—Ä–æ–π –∫–æ–º–ø–∞–∫—Ç-–¥–∏—Å–∫?\", \"–ß—Ç–æ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –Ω–∞ –≤—Ç–æ—Ä–æ–º –¥–∏—Å–∫–µ?\", \"–ß—Ç–æ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –Ω–∞ –≤—Ç–æ—Ä–æ–º –∫–æ–º–ø–∞–∫—Ç-–¥–∏—Å–∫–µ?\", \"–ö–∞–∫–∏–µ –¥–∏—Å–∫–∏ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å?\", \"CD –∏–ª–∏ DVD –¥–∏—Å–∫–∏?\"], \"responses\": [\"üíøüìÄ–ù–∞ –Ω–æ—Ä–º–æ–∫–æ–Ω—Ç—Ä–æ–ª—å –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏—Ç—å –¥–≤–∞ –∫–æ–º–ø–∞–∫—Ç-–¥–∏—Å–∫–∞ (CD –∏–ª–∏ DVD ‚Äì –Ω–µ –≤–∞–∂–Ω–æ) –∏ –¥–≤–µ —ç—Ç–∏–∫–µ—Ç–∫–∏, –ø–æ–¥–ø–∏—Å–∞–Ω–Ω—ã–µ —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª–µ–º.\", \"\\t\\t‚ó¶ –Ω–∞ –ø–µ—Ä–≤—ã–π –¥–∏—Å–∫ –Ω—É–∂–Ω–æ –∑–∞–ø–∏—Å–∞—Ç—å: –ü–ó –≤ —Ñ–æ—Ä–º–∞—Ç–µ pdf (–æ–¥–Ω–∏–º —Ñ–∞–π–ª–æ–º! –§–∞–π–ª —Å –ü–ó –¥–æ–ª–∂–µ–Ω –≤–∫–ª—é—á–∞—Ç—å –≤ —Å–µ–±—è –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω—ã–π —Ç–∏—Ç—É–ª—å–Ω—ã–π –ª–∏—Å—Ç, –∑–∞–¥–∞–Ω–∏–µ, –∞–Ω–Ω–æ—Ç–∞—Ü–∏—é, —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ, —Å–∞–º—É —Ä–∞–±–æ—Ç—É, —Å–ø–∏—Å–æ–∫ –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä—ã –∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è), –ø—Ä–æ–≥—Ä–∞–º–º–Ω—ã–π –ø—Ä–æ–¥—É–∫—Ç, –≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–π –º–∞—Ç–µ—Ä–∏–∞–ª –≤ —Ñ–æ—Ä–º–∞—Ç–µ pdf (–∑–∞–ø–∏—Å—ã–≤–∞–µ–º –æ–¥–Ω–∏–º —Ñ–∞–π–ª–æ–º!), —Ä–µ–∫–ª–∞–º–Ω—ã–π –ø—Ä–æ—Å–ø–µ–∫—Ç, —ç—Ç–∏–∫–µ—Ç–∫–∞ –í–ö–†.\", \"\\t\\t‚ó¶ –Ω–∞ –≤—Ç–æ—Ä–æ–π –¥–∏—Å–∫ –Ω—É–∂–Ω–æ –∑–∞–ø–∏—Å–∞—Ç—å –≤—Å—ë —Ç–æ –∂–µ —Å–∞–º–æ–µ, –∑–∞ –∏—Å–∫–ª—é—á–µ–Ω–∏–µ–º –ø—Ä–æ–≥—Ä–∞–º–º–Ω–æ–≥–æ –ø—Ä–æ–¥—É–∫—Ç–∞.\"]}, \"graphic part\": {\"examples\": [\"–ß—Ç–æ —Ç–∞–∫–æ–µ –≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∞—è —á–∞—Å—Ç—å?\", \"–ß—Ç–æ —Ç–∞–∫–æ–µ —Ä–∞–∑–¥–∞—Ç–æ—á–Ω—ã–π –º–∞—Ç–µ—Ä–∏–∞–ª?\", \"–ß—Ç–æ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –∏–∑ —Å–µ–±—è –≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∞—è —á–∞—Å—Ç—å?\", \"–ß—Ç–æ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –∏–∑ —Å–µ–±—è —Ä–∞–∑–¥–∞—Ç–æ—á–Ω—ã–π –º–∞—Ç–µ—Ä–∏–∞–ª?\", \"–ö–∞–∫ –æ—Ñ–æ—Ä–º–∏—Ç—å –≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–π –º–∞—Ç–µ—Ä–∏–∞–ª?\", \"–ö–∞–∫ –æ—Ñ–æ—Ä–º–∏—Ç—å —Ä–∞–∑–¥–∞—Ç–æ—á–Ω—ã–π –º–∞—Ç–µ—Ä–∏–∞–ª?\", \"–ö—Ç–æ –¥–æ–ª–∂–µ–Ω –ø–æ–¥–ø–∏—Å–∞—Ç—å –≥—Ä–∞—Ñ–∏—á–µ—Å–∫—É—é —á–∞—Å—Ç—å?\", \"–ß—å–∏ –ø–æ–¥–ø–∏—Å–∏ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –Ω–∞ –≥—Ä–∞—Ñ–∏—á–µ—Å–∫–æ–π —á–∞—Å—Ç–∏?\", \"–ö—Ç–æ –¥–æ–ª–∂–µ–Ω –ø–æ–¥–ø–∏—Å–∞—Ç—å —Ä–∞–∑–¥–∞—Ç–æ—á–Ω—ã–π –º–∞—Ç–µ—Ä–∏–∞–ª?\", \"–ß—å–∏ –ø–æ–¥–ø–∏—Å–∏ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –Ω–∞ —Ä–∞–∑–¥–∞—Ç–æ—á–Ω–æ–º –º–∞—Ç–µ—Ä–∏–∞–ª–µ?\", \"–ò–∑ —á–µ–≥–æ —Å–æ—Å—Ç–æ–∏—Ç –≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∞—è —á–∞—Å—Ç—å?\", \"–ò–∑ —á–µ–≥–æ —Å–æ—Å—Ç–æ–∏—Ç —Ä–∞–∑–¥–∞—Ç–æ—á–Ω—ã–π –º–∞—Ç–µ—Ä–∏–∞–ª?\", \"–ö–∞–∫–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—é –≥—Ä–∞—Ñ–∏—á–µ—Å–∫–æ–π —á–∞—Å—Ç–∏?\", \"–ö–∞–∫–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—é —Ä–∞–∑–¥–∞—Ç–æ—á–Ω–æ–≥–æ –º–∞—Ç–µ—Ä–∏–∞–ª–∞? \"], \"responses\": [\"üìä–ì—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–π –º–∞—Ç–µ—Ä–∏–∞–ª –∏ —Ä–∞–∑–¥–∞—Ç–æ—á–Ω—ã–π –º–∞—Ç–µ—Ä–∏–∞–ª –ø–æ–ª—É—á–∞—é—Ç—Å—è –∏–∑ –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–∏ –∫ –≤—ã—Å—Ç—É–ø–ª–µ–Ω–∏—é.\", \"\\t\\t–ì—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–π –º–∞—Ç–µ—Ä–∏–∞–ª ‚Äì —ç—Ç–æ —Å–ª–∞–π–¥—ã –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–∏. –ü—Ä–∏—á–µ–º, –∫–∞–∂–¥—ã–π —Å–ª–∞–π–¥ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤ —Ä–∞–º–∫–µ, –∞ —Ç–∞–∫–∂–µ –≤ –≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–π –º–∞—Ç–µ—Ä–∏–∞–ª –Ω–µ –≤–∫–ª—é—á–∞—é—Ç—Å—è –ø–µ—Ä–≤—ã–π (—Å –Ω–∞–∑–≤–∞–Ω–∏–µ–º —Ä–∞–±–æ—Ç—ã) –∏ –ø–æ—Å–ª–µ–¥–Ω–∏–π (¬´—Å–ø–∞—Å–∏–±–æ –∑–∞ –≤–Ω–∏–º–∞–Ω–∏–µ¬ª) —Å–ª–∞–π–¥—ã. –ù–∞ –∫–∞–∂–¥–æ–º –ø–ª–∞–∫–∞—Ç–µ –≥—Ä–∞—Ñ–∏—á–µ—Å–∫–æ–≥–æ –º–∞—Ç–µ—Ä–∏–∞–ª–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –ø–æ–¥–ø–∏—Å—å:\", \"- —Å—Ç—É–¥–µ–Ω—Ç–∞ –∏ —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—è (–¥–ª—è –±–∞–∫–∞–ª–∞–≤—Ä–æ–≤);\", \"- —Å—Ç—É–¥–µ–Ω—Ç–∞, —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—è –∏ —Ä–µ—Ü–µ–Ω–∑–µ–Ω—Ç–∞ (–¥–ª—è –º–∞–≥–∏—Å—Ç—Ä–∞–Ω—Ç–æ–≤).\", \"\\t\\t–†–∞–∑–¥–∞—Ç–æ—á–Ω—ã–π –º–∞—Ç–µ—Ä–∏–∞–ª ‚Äì —Ä–∞—Å–ø–µ—á–∞—Ç–∞–Ω–Ω–∞—è –≤ 5 —ç–∫–∑–µ–º–ø–ª—è—Ä–∞—Ö –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏—è (–±–µ–∑ —Ä–∞–º–æ–∫). \"]}, \"anti-plagiarism\": {\"examples\": [\"–ß—Ç–æ —Ç–∞–∫–æ–µ –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∞–Ω—Ç–∏–ø–ª–∞–≥–∏–∞—Ç?\", \"–ß—Ç–æ —Ç–∞–∫–æ–µ –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø–ª–∞–≥–∏–∞—Ç?\", \"–ß—Ç–æ –∏–∑ —Å–µ–±—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø–ª–∞–≥–∏–∞—Ç?\", \"–ß—Ç–æ –∏–∑ —Å–µ–±—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∞–Ω—Ç–∏–ø–ª–∞–≥–∏–∞—Ç?\", \"–í —á—ë–º –∑–∞–∫–ª—é—á–∞–µ—Ç—Å—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø–ª–∞–≥–∏–∞—Ç?\", \"–í —á—ë–º –∑–∞–∫–ª—é—á–∞–µ—Ç—Å—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∞–Ω—Ç–∏–ø–ª–∞–≥–∏–∞—Ç?\", \"–ö–∞–∫–æ–π –ø—Ä–æ—Ü–µ–Ω—Ç —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏ —Ç–µ–∫—Å—Ç–∞?\", \"–ö—Ç–æ –≥–æ—Ç–æ–≤–∏—Ç —Å–ø—Ä–∞–≤–∫—É –æ–± –∞–Ω—Ç–∏–ø–ª–∞–≥–∏–∞—Ç–µ?\", \"–ö—Ç–æ –æ—Ñ–æ—Ä–º–ª—è–µ—Ç —Å–ø—Ä–∞–≤–∫—É –æ–± –∞–Ω—Ç–∏–ø–ª–∞–≥–∏–∞—Ç–µ?\", \"–ö—Ç–æ –ø–æ–¥–ø–∏—Å—ã–≤–∞–µ—Ç —Å–ø—Ä–∞–≤–∫—É –æ–± –∞–Ω—Ç–∏–ø–ª–∞–≥–∏–∞—Ç–µ?\", \"–ö—Ç–æ —Ä–∞—Å–ø–∏—Å—ã–≤–∞–µ—Ç—Å—è –Ω–∞ —Å–ø—Ä–∞–≤–∫–µ –æ–± –∞–Ω—Ç–∏–ø–ª–∞–≥–∏–∞—Ç–µ?\", \"–ß—å—è –ø–æ–¥–ø–∏—Å—å –Ω—É–∂–Ω–∞ –¥–ª—è —Å–ø—Ä–∞–≤–∫–∏ –æ–± –∞–Ω—Ç–∏–ø–ª–∞–≥–∏–∞—Ç–µ?\"], \"responses\": [\"üö´–ü–ª–∞–≥–∏–∞—Ç ‚Äì —ç—Ç–æ —Å–∫–æ–ø–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç, –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã–π –Ω–∞ –¥—Ä—É–≥–æ–º —Å–∞–π—Ç–µ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π.\", \"\\t\\t–ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç –∞–Ω—Ç–∏–ø–ª–∞–≥–∏–∞—Ç? –û–±—ã—á–Ω–æ —ç—Ç–æ –≤–µ–±-—Å–µ—Ä–≤–∏—Å –∏–ª–∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ, –≤ –∫–æ—Ç–æ—Ä–æ–µ –∞–≤—Ç–æ—Ä –∑–∞–≥—Ä—É–∂–∞–µ—Ç —Å–≤–æ–π —Ç–µ–∫—Å—Ç, –∞ –Ω–∞ –≤—ã—Ö–æ–¥–µ –ø–æ–ª—É—á–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω–æ–≥–æ –∏ –∑–∞–∏–º—Å—Ç–≤–æ–≤–∞–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –≤ –ø—Ä–æ—Ü–µ–Ω—Ç–Ω–æ–º —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–∏.\", \"\\t\\t–î–ª—è –±–∞–∫–∞–ª–∞–≤—Ä–æ–≤ –ø—Ä–æ—Ü–µ–Ω—Ç —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏ —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç 65%, –¥–ª—è –º–∞–≥–∏—Å—Ç—Ä–∞–Ω—Ç–æ–≤ - 75%.\", \"\\t\\t–°–ø—Ä–∞–≤–∫–∞ –æ–± –∞–Ω—Ç–∏–ø–ª–∞–≥–∏–∞—Ç–µ –≥–æ—Ç–æ–≤–∏—Ç—Å—è –∏ –ø–æ–¥–ø–∏—Å—ã–≤–∞–µ—Ç—Å—è —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª–µ–º.\"]}, \"review\": {\"examples\": [\"–ö—Ç–æ –ø–æ–¥–ø–∏—Å—ã–≤–∞–µ—Ç —Ä–µ—Ü–µ–Ω–∑–∏—é?\", \"–ß—å–∏ –ø–æ–¥–ø–∏—Å–∏ –Ω—É–∂–Ω—ã –¥–ª—è —Ä–µ—Ü–µ–Ω–∑–∏–∏?\", \"–ù—É–∂–Ω–∞ –ª–∏ —Ä–µ—Ü–µ–Ω–∑–∏—è –¥–ª—è –±–∞–∫–∞–ª–∞–≤—Ä–æ–≤?\", \"–î–ª—è –±–∞–∫–∞–ª–∞–≤—Ä–∏–∞—Ç–∞ –Ω—É–∂–Ω–∞ —Ä–µ—Ü–µ–Ω–∑–∏—è?\", \"–ë–∞–∫–∞–ª–∞–≤—Ä—É –Ω—É–∂–Ω–∞ —Ä–µ—Ü–µ–Ω–∑–∏—è?\", \"–ù—É–∂–Ω–∞ –ª–∏ –ø–µ—á–∞—Ç—å –ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏—è –¥–ª—è —Ä–µ—Ü–µ–Ω–∑–∏–∏?\", \"–ö–∞–∫ —Å–æ—Å—Ç–∞–≤–∏—Ç—å —Ä–µ—Ü–µ–Ω–∑–∏—é?\", \"–ö–∞–∫ –∑–∞–ø–æ–ª–Ω–∏—Ç—å —Ä–µ—Ü–µ–Ω–∑–∏—é?\"], \"responses\": [\"üìÑ–†–µ—Ü–µ–Ω–∑–∏—è –Ω–µ–æ–±—Ö–æ–¥–∏–º–∞ —Ç–æ–ª—å–∫–æ –¥–ª—è –º–∞–≥–∏—Å—Ç—Ä–∞–Ω—Ç–æ–≤. –†–µ—Ü–µ–Ω–∑–∏—è –≥–æ—Ç–æ–≤–∏—Ç—Å—è –∏ –ø–æ–¥–ø–∏—Å—ã–≤–∞–µ—Ç—Å—è —Ä–µ—Ü–µ–Ω–∑–µ–Ω—Ç–æ–º (—Ä–µ—Ü–µ–Ω–∑–∏—è –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —Å—Ç–æ—Ä–æ–Ω–Ω—è—è –∏ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ —Å –ø–µ—á–∞—Ç—å—é –ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏—è).\"]}, \"greeting\": {\"examples\": [\"–ü—Ä–∏–≤–µ—Ç–∏–∫–∏\", \"–ü—Ä–∏–≤–µ—Ç–∏–∫\", \"–î–æ–±—Ä–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ —Å—É—Ç–æ–∫\", \"–ü—Ä–∏–≤–µ—Ç—Å—Ç–≤—É—é\", \"–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ\", \"–†–∞–¥ –≤–∞—Å —Å–ª—ã—à–∞—Ç—å\", \"–î–æ–±—Ä–æ–µ —É—Ç—Ä–æ\", \"–î–æ–±—Ä—ã–π –¥–µ–Ω—å\", \"–î–æ–±—Ä—ã–π –≤–µ—á–µ—Ä\", \"–ü—Ä–∏–≤–µ—Ç\", \"–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π\", \"–ë–æ—Ç\"], \"responses\": [\"–î–æ–±—Ä–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ —Å—É—Ç–æ–∫!üëã\", \"–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π.üëã\", \"–†–∞–¥ –≤–∞—Å —Å–ª—ã—à–∞—Ç—å!üòÄ\", \"–ü—Ä–∏–≤–µ—Ç—Å—Ç–≤—É—é!üëã\", \"–î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å.üëã\"]}, \"gratitude\": {\"examples\": [\"–°–ø–∞—Å–∏–±–æ\", \"–°–ø–∞—Å–∏–±–æ –±–æ–ª—å—à–æ–µ\", \"–ë–ª–∞–≥–æ–¥–∞—Ä—é\", \"–í–µ—Å—å–º–∞ –ø—Ä–∏–∑–Ω–∞—Ç–µ–ª–µ–Ω\", \"–ü—Ä–µ–º–Ω–æ–≥–æ –±–ª–∞–≥–æ–¥–∞—Ä–µ–Ω\", \"–°–ø–∞—Å–∏–±–æ, –≤—ã—Ä—É—á–∏–ª\", \"–°–ø–∞—Å–∏–±–æ –∑–∞ –ø–æ–º–æ—â—å\", \"–ë–ª–∞–≥–æ–¥–∞—Ä—Å—Ç–≤—É—é\"], \"responses\": [\"–í—Å–µ–≥–¥–∞ —Ä–∞–¥ –ø–æ–º–æ—á—å!üòä\", \"–£—Å–ø–µ—Ö–æ–≤!\", \"–û–±—Ä–∞—â–∞–π—Ç–µ—Å—å –≤ –ª—é–±–æ–µ –≤—Ä–µ–º—è.üòÅ\", \"–ü–æ–∂–∞–ª—É–π—Å—Ç–∞!üòä\", \"–° –≤–∞–º–∏ –ø—Ä–∏—è—Ç–Ω–æ –∏–º–µ—Ç—å –¥–µ–ª–æ.üòâ\", \"–ò –≤–∞–º —Å–ø–∞—Å–∏–±–æ. –ü—Ä–∏—Ö–æ–¥–∏—Ç–µ —Å–Ω–æ–≤–∞!\", \"–ú–Ω–µ –±—ã–ª–æ –ø—Ä–∏—è—Ç–Ω–æ –ø–æ–º–æ—á—å –≤–∞–º.üòâ\"]}, \"goodbye\": {\"examples\": [\"–ü–æ–∫–∞\", \"–ü–æ–∫–∏\", \"–ü–æ–∫–∞-–ø–æ–∫–∞\", \"–ü—Ä–æ—â–∞–π\", \"–•–æ—Ä–æ—à–µ–≥–æ –¥–Ω—è\", \"–î–æ –≤—Å—Ç—Ä–µ—á–∏\", \"–î–æ —Å–≤–∏–¥–∞–Ω–∏—è\", \"–î–æ –Ω–æ–≤–æ–π –≤—Å—Ç—Ä–µ—á–∏\", \"–°—á–∞—Å—Ç–ª–∏–≤–æ\", \"–î–æ —Å–∫–æ—Ä–æ–π –≤—Å—Ç—Ä–µ—á–∏\", \"–î–æ –∑–∞–≤—Ç—Ä–∞\", \"–í—Å–µ–≥–æ –¥–æ–±—Ä–æ–≥–æ\", \"–í—Å–µ–≥–æ —Ö–æ—Ä–æ—à–µ–≥–æ\", \"–ü—Ä–æ—â–∞–π—Ç–µ\"], \"responses\": [\"–í—Å–µ–≥–æ –¥–æ–±—Ä–æ–≥–æ!üòâ\", \"–£–¥–∞—á–∏!\", \"–î–æ —Å–≤–∏–¥–∞–Ω–∏—è!\", \"–î–æ –≤—Å—Ç—Ä–µ—á–∏!üòâ\", \"–£–≤–∏–¥–∏–º—Å—è.üòâ\"]}, \"feedback\": {\"examples\": [\"–ö—Ç–æ –≥–æ—Ç–æ–≤–∏—Ç –æ—Ç–∑—ã–≤ —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—è?\", \"–ö—Ç–æ —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç –æ—Ç–∑—ã–≤ —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—è?\", \"–ö—Ç–æ –æ—Ç–≤–µ—á–∞–µ—Ç –∑–∞ –æ—Ç–∑—ã–≤ —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—è?\", \"–ö–∞–∫ –Ω–∞–ø–∏—Å–∞—Ç—å –æ—Ç–∑—ã–≤ —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—è?\", \"–ö–∞–∫ —Å–æ—Å—Ç–∞–≤–∏—Ç—å –æ—Ç–∑—ã–≤ —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—è?\", \"–ö–∞–∫ –∑–∞–ø–æ–ª–Ω–∏—Ç—å –æ—Ç–∑—ã–≤ —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—è?\"], \"responses\": [\"üìÑ–û—Ç–∑—ã–≤ —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—è –≥–æ—Ç–æ–≤–∏—Ç—Å—è —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª–µ–º.\"]}, \"time&place\": {\"examples\": [\"–ö–æ–≥–¥–∞ –±—É–¥–µ—Ç –Ω–æ—Ä–º–æ–∫–æ–Ω—Ç—Ä–æ–ª—å?\", \"–ö–æ–≥–¥–∞ –±—É–¥–µ—Ç –ø—Ä–æ—Ö–æ–¥–∏—Ç—å –Ω–æ—Ä–º–æ–∫–æ–Ω—Ç—Ä–æ–ª—å?\", \"–ì–¥–µ –±—É–¥–µ—Ç –Ω–æ—Ä–º–æ–∫–æ–Ω—Ç—Ä–æ–ª—å?\", \"–ì–¥–µ –±—É–¥–µ—Ç –ø—Ä–æ—Ö–æ–¥–∏—Ç—å –Ω–æ—Ä–º–æ–∫–æ–Ω—Ç—Ä–æ–ª—å?\", \"–í –∫–∞–∫–æ–º –∫–æ—Ä–ø—É—Å–µ –±—É–¥–µ—Ç –Ω–æ—Ä–º–æ–∫–æ–Ω—Ç—Ä–æ–ª—å?\", \"–í –∫–∞–∫–æ–º –∫–æ—Ä–ø—É—Å–µ –±—É–¥–µ—Ç –ø—Ä–æ—Ö–æ–¥–∏—Ç—å –Ω–æ—Ä–º–æ–∫–æ–Ω—Ç—Ä–æ–ª—å?\", \"–í –∫–∞–∫–æ–π –∞—É–¥–∏—Ç–æ—Ä–∏–∏ –±—É–¥–µ—Ç –Ω–æ—Ä–º–æ–∫–æ–Ω—Ç—Ä–æ–ª—å?\", \"–í –∫–∞–∫–æ–π –∞—É–¥–∏—Ç–æ—Ä–∏–∏ –±—É–¥–µ—Ç –ø—Ä–æ—Ö–æ–¥–∏—Ç—å –Ω–æ—Ä–º–æ–∫–æ–Ω—Ç—Ä–æ–ª—å?\", \"–í –∫–∞–∫–æ–µ –≤—Ä–µ–º—è –±—É–¥–µ—Ç –Ω–æ—Ä–º–æ–∫–æ–Ω—Ç—Ä–æ–ª—å?\", \"–í –∫–∞–∫–æ–µ –≤—Ä–µ–º—è –±—É–¥–µ—Ç –ø—Ä–æ—Ö–æ–¥–∏—Ç—å –Ω–æ—Ä–º–æ–∫–æ–Ω—Ç—Ä–æ–ª—å?\"], \"responses\": [\"üìÖ–†–∞—Å–ø–∏—Å–∞–Ω–∏–µ –ø–æ—è–≤–∏—Ç—Å—è –ø–æ–∑–∂–µ\"]}}, 'failure_phrases':['–£—Ç–æ—á–Ω–∏—Ç–µ —Å–≤–æ–π –≤–æ–ø—Ä–æ—Å, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞.', '–ü–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π—Ç–µ, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞.', '–ü–µ—Ä–µ—Ñ—Ä–∞–∑–∏—Ä—É–π—Ç–µ, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞.', '–ü—Ä–æ—Å—Ç–∏—Ç–µ, –Ω–µ –ø–æ–Ω—è–ª –≤–∞—Å. –°—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π—Ç–µ –ø–æ-–¥—Ä—É–≥–æ–º—É —Å–≤–æ–π –≤–æ–ø—Ä–æ—Å.', '–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Å—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π—Ç–µ —Å–≤–æ–π –≤–æ–ø—Ä–æ—Å –∏–Ω–∞—á–µ.', '–ù–µ –ø–æ–Ω—è–ª —Å–º—ã—Å–ª–∞ –≤–∞—à–µ–≥–æ –≤–æ–ø—Ä–æ—Å–∞. –ü–µ—Ä–µ—Ñ—Ä–∞–∑–∏—Ä—É–π—Ç–µ, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞.']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "a5W9XyFR9gkz"
   },
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem\n",
    "from pyaspeller import YandexSpeller\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "JQcIMoKyH6q8"
   },
   "outputs": [],
   "source": [
    "# –õ–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è\n",
    "def form_of_word(text):\n",
    "    m3 = Mystem()\n",
    "    text = ''.join(m3.lemmatize(text)).rstrip('\\n')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "cYVfOdeCuugL"
   },
   "outputs": [],
   "source": [
    "# –£–¥–∞–ª–µ–Ω–∏–µ —Å–∏–º–≤–æ–ª–æ–≤ –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏\n",
    "def remove_punctuation(text):\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    return text.translate(translator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "xGxLLvgChvnN",
    "outputId": "8beb2f9e-de97-413d-c1eb-9d329e716cd1"
   },
   "outputs": [],
   "source": [
    "# –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞\n",
    "dataset = []  # [[x, y], [example, intent], ...]\n",
    "for intent, intent_data in BOT_CONFIG['intents'].items():\n",
    "    for example in intent_data['examples']:\n",
    "        example = example.lower()\n",
    "        example = remove_punctuation(example)\n",
    "        example = form_of_word(example)\n",
    "        dataset.append([example, intent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "WmLRKQlohvnO"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['—á—Ç–æ —ç—Ç–æ –Ω–æ—Ä–º–æ–∫–æ–Ω—Ç—Ä–æ–ª—å', 'normocontrol'],\n",
       " ['—á—Ç–æ –±—ã—Ç—å —Ç–∞–∫–æ–π –Ω–æ—Ä–º–æ–∫–æ–Ω—Ç—Ä–æ–ª—å', 'normocontrol'],\n",
       " ['—á—Ç–æ —Ç–∞–∫–æ–π –Ω–æ—Ä–º–æ–∫–æ–Ω—Ç—Ä–æ–ª—å', 'normocontrol'],\n",
       " ['–∫–∞–∫ –ø—Ä–æ—Ö–æ–¥–∏—Ç—å –Ω–æ—Ä–º–æ–∫–æ–Ω—Ç—Ä–æ–ª—å', 'normocontrol'],\n",
       " ['—á—Ç–æ –∏–∑ —Å–µ–±—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—Ç—å –Ω–æ—Ä–º–æ–∫–æ–Ω—Ç—Ä–æ–ª—å', 'normocontrol'],\n",
       " ['—á—Ç–æ –Ω—É–∂–Ω—ã–π –¥–ª—è –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏–µ –Ω–æ—Ä–º–∫–æ–Ω—Ç—Ä–æ–ª—å', 'normocontrol'],\n",
       " ['—á—Ç–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –¥–ª—è –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏–µ –Ω–æ—Ä–º–∫–æ–Ω—Ç—Ä–æ–ª—å', 'normocontrol'],\n",
       " ['—á—Ç–æ —Ç—Ä–µ–±–æ–≤–∞—Ç—å—Å—è –¥–ª—è –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏–µ –Ω–æ—Ä–º–∫–æ–Ω—Ç—Ä–æ–ª—å', 'normocontrol'],\n",
       " ['–¥–ª—è —á—Ç–æ –Ω—É–∂–Ω—ã–π –Ω–æ—Ä–º–æ–∫–æ–Ω—Ç—Ä–æ–ª—å', 'normocontrol'],\n",
       " ['–∫–∞–∫ –ø—Ä–æ—Ö–æ–¥–∏—Ç—å –Ω–æ—Ä–º–æ–∫–æ–Ω—Ç—Ä–æ–ª—å', 'normocontrol'],\n",
       " ['—á—Ç–æ –≤–∫–ª—é—á–∞—Ç—å –≤ —Å–µ–±—è –Ω–æ—Ä–º–æ–∫–æ–Ω—Ç—Ä–æ–ª—å', 'normocontrol'],\n",
       " ['—á—Ç–æ –≤—Ö–æ–¥–∏—Ç—å –≤ –Ω–æ—Ä–º–æ–∫–æ–Ω—Ç—Ä–æ–ª—å', 'normocontrol'],\n",
       " ['–∫–∞–∫ –±—ã—Ç—å –ø—Ä–æ—Ö–æ–¥–∏—Ç—å –Ω–æ—Ä–º–æ–∫–æ–Ω—Ç—Ä–æ–ª—å', 'normocontrol'],\n",
       " ['—á—Ç–æ –±—ã—Ç—å –≤—Ö–æ–¥–∏—Ç—å –≤ –Ω–æ—Ä–º–æ–∫–æ–Ω—Ç—Ä–æ–ª—å', 'normocontrol'],\n",
       " ['—á—Ç–æ –±—ã—Ç—å –≤–∫–ª—é—á–∞—Ç—å –≤ –Ω–æ—Ä–º–æ–∫–æ–Ω—Ç—Ä–æ–ª—å', 'normocontrol'],\n",
       " ['—á—Ç–æ –ø–æ—Ç—Ä–µ–±–æ–≤–∞—Ç—å—Å—è –¥–ª—è –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏–µ –Ω–æ—Ä–º–∫–æ–Ω—Ç—Ä–æ–ª—å', 'normocontrol'],\n",
       " ['—á—Ç–æ –∏–∑ —Å–µ–±—è –±—ã—Ç—å –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—Ç—å –Ω–æ—Ä–º–æ–∫–æ–Ω—Ç—Ä–æ–ª—å', 'normocontrol'],\n",
       " ['—á—Ç–æ –±—ã—Ç—å –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–π –¥–ª—è –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏–µ –Ω–æ—Ä–º–∫–æ–Ω—Ç—Ä–æ–ª—å', 'normocontrol'],\n",
       " ['—á—Ç–æ –±—ã—Ç—å –Ω—É–∂–Ω–æ –¥–ª—è –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏–µ –Ω–æ—Ä–º–∫–æ–Ω—Ç—Ä–æ–ª—å', 'normocontrol'],\n",
       " ['—á—Ç–æ –±—ã—Ç—å –≤–∫–ª—é—á–∞—Ç—å –≤ —Å–µ–±—è –Ω–æ—Ä–º–æ–∫–æ–Ω—Ç—Ä–æ–ª—å', 'normocontrol'],\n",
       " ['—Å–∫–∏–¥—ã–≤–∞—Ç—å –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç –¥–ª—è –Ω–æ—Ä–º–∫–æ–Ω—Ç—Ä–æ–ª—å', 'normocontrol'],\n",
       " ['—Å–∫–∏–¥—ã–≤–∞—Ç—å –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç –¥–ª—è –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏–µ –Ω–æ—Ä–º–∫–æ–Ω—Ç—Ä–æ–ª—å',\n",
       "  'normocontrol'],\n",
       " ['—Å–∫–∏–¥—ã–≤–∞—Ç—å –Ω–æ—Ä–º–∞—Ç–∏–≤ –¥–ª—è –Ω–æ—Ä–º–∫–æ–Ω—Ç—Ä–æ–ª—å', 'normocontrol'],\n",
       " ['–≥–¥–µ –Ω–∞—Ö–æ–¥–∏—Ç—å –Ω–æ—Ä–º–∞—Ç–∏–≤ –¥–ª—è –Ω–æ—Ä–º–∫–æ–Ω—Ç—Ä–æ–ª—å', 'normocontrol'],\n",
       " ['–≥–¥–µ –Ω–∞—Ö–æ–¥–∏—Ç—å –Ω–æ—Ä–º–∞—Ç–∏–≤ –¥–ª—è –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏–µ –Ω–æ—Ä–º–∫–æ–Ω—Ç—Ä–æ–ª—å', 'normocontrol'],\n",
       " ['–≥–¥–µ –Ω–∞—Ö–æ–¥–∏—Ç—å –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç –¥–ª—è –Ω–æ—Ä–º–∫–æ–Ω—Ç—Ä–æ–ª—å', 'normocontrol'],\n",
       " ['–≥–¥–µ –Ω–∞—Ö–æ–¥–∏—Ç—å –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç –¥–ª—è –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏–µ –Ω–æ—Ä–º–∫–æ–Ω—Ç—Ä–æ–ª—å',\n",
       "  'normocontrol'],\n",
       " ['–≤—ã—Ö–æ–¥–∏—Ç—å –Ω–æ—Ä–º–∞—Ç–∏–≤ –¥–ª—è –Ω–æ—Ä–º–∫–æ–Ω—Ç—Ä–æ–ª—å', 'normocontrol'],\n",
       " ['–≤—ã—Ö–æ–¥–∏—Ç—å –Ω–æ—Ä–º–∞—Ç–∏–≤ –¥–ª—è –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏–µ –Ω–æ—Ä–º–∫–æ–Ω—Ç—Ä–æ–ª—å', 'normocontrol'],\n",
       " ['–≤—ã—Ö–æ–¥–∏—Ç—å –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç –¥–ª—è –Ω–æ—Ä–º–∫–æ–Ω—Ç—Ä–æ–ª—å', 'normocontrol'],\n",
       " ['–≤—ã—Ö–æ–¥–∏—Ç—å –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç –¥–ª—è –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏–µ –Ω–æ—Ä–º–∫–æ–Ω—Ç—Ä–æ–ª—å',\n",
       "  'normocontrol'],\n",
       " ['–∫–∞–∫ –æ—Ñ–æ—Ä–º–ª—è—Ç—å —Ç–∏—Ç—É–ª—å–Ω–∏–∫', 'title'],\n",
       " ['–∫–∞–∫ –æ—Ñ–æ—Ä–º–ª—è—Ç—å —Ç–∏—Ç—É–ª—å–Ω—ã–π –ª–∏—Å—Ç', 'title'],\n",
       " ['–∫–∞–∫–æ–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏–µ —Ç–∏—Ç—É–ª—å–Ω—ã–π –ª–∏—Å—Ç', 'title'],\n",
       " ['–∫–∞–∫–æ–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏–µ —Ç–∏—Ç—É–ª—å–Ω–∏–∫', 'title'],\n",
       " ['—á–µ–π –ø–æ–¥–ø–∏—Å—å –Ω—É–∂–Ω—ã–π –Ω–∞ —Ç–∏—Ç—É–ª—å–Ω—ã–π –ª–∏—Å—Ç', 'title'],\n",
       " ['—á–µ–π –ø–æ–¥–ø–∏—Å—å –Ω—É–∂–Ω—ã–π –Ω–∞ —Ç–∏—Ç—É–ª—å–Ω–∏–∫', 'title'],\n",
       " ['–∫—Ç–æ –¥–æ–ª–∂–Ω—ã–π —Ä–∞—Å–ø–∏—Å—ã–≤–∞—Ç—å—Å—è –Ω–∞ —Ç–∏—Ç—É–ª—å–Ω—ã–π –ª–∏—Å—Ç', 'title'],\n",
       " ['–∫—Ç–æ –¥–æ–ª–∂–Ω—ã–π —Ä–∞—Å–ø–∏—Å—ã–≤–∞—Ç—å—Å—è –Ω–∞ —Ç–∏—Ç—É–ª—å–Ω–∏–∫', 'title'],\n",
       " ['–∫–∞–∫ –¥–æ–ª–∂–Ω—ã–π –±—ã—Ç—å –æ—Ñ–æ—Ä–º–ª—è—Ç—å —Ç–∏—Ç—É–ª—å–Ω—ã–π –ª–∏—Å—Ç', 'title'],\n",
       " ['–∫–∞–∫ –¥–æ–ª–∂–Ω—ã–π –±—ã—Ç—å –æ—Ñ–æ—Ä–º–ª—è—Ç—å —Ç–∏—Ç—É–ª—å–Ω–∏–∫', 'title'],\n",
       " ['–∫–∞–∫ –∑–∞–ø–æ–ª–Ω—è—Ç—å —Ç–∏—Ç—É–ª—å–Ω—ã–π –ª–∏—Å—Ç', 'title'],\n",
       " ['–∫–∞–∫ –∑–∞–ø–æ–ª–Ω—è—Ç—å —Ç–∏—Ç—É–ª—å–Ω–∏–∫', 'title'],\n",
       " ['–∫–∞–∫ –¥–æ–ª–∂–Ω—ã–π –±—ã—Ç—å –∑–∞–ø–æ–ª–Ω—è—Ç—å —Ç–∏—Ç—É–ª—å–Ω—ã–π –ª–∏—Å—Ç', 'title'],\n",
       " ['–∫–∞–∫ –¥–æ–ª–∂–Ω—ã–π –±—ã—Ç—å –∑–∞–ø–æ–ª–Ω—è—Ç—å —Ç–∏—Ç—É–ª—å–Ω–∏–∫', 'title'],\n",
       " ['–∫–∞–∫ –æ—Ñ–æ—Ä–º–ª—è—Ç—å –∑–∞–¥–∞–Ω–∏–µ –∫ –≤–∫—Ä', 'task'],\n",
       " ['–∫–∞–∫ –æ—Ñ–æ—Ä–º–ª—è—Ç—å –∑–∞–¥–∞–Ω–∏–µ –∫ –¥–∏–ø–ª–æ–º', 'task'],\n",
       " ['–∫–∞–∫ –æ—Ñ–æ—Ä–º–ª—è—Ç—å –¥–∏–ø–ª–æ–º–Ω—ã–π –∑–∞–¥–∞–Ω–∏–µ', 'task'],\n",
       " ['–∫–∞–∫–æ–π —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–µ –∫ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏–µ –∑–∞–¥–∞–Ω–∏–µ –∫ –≤–∫—Ä', 'task'],\n",
       " ['–∫–∞–∫–æ–π —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–µ –∫ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏–µ –∑–∞–¥–∞–Ω–∏–µ –ø–æ –¥–∏–ø–ª–æ–º', 'task'],\n",
       " ['–∫–∞–∫–æ–π —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–µ –∫ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏–µ –¥–∏–ø–ª–æ–º–Ω—ã–π –∑–∞–¥–∞–Ω–∏–µ', 'task'],\n",
       " ['–∫–∞–∫–æ–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏–µ –∑–∞–¥–∞–Ω–∏–µ –∫ –≤–∫—Ä', 'task'],\n",
       " ['–∫–∞–∫–æ–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏–µ –¥–∏–ø–ª–æ–º–Ω—ã–π –∑–∞–¥–∞–Ω–∏–µ', 'task'],\n",
       " ['–∫–∞–∫–æ–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏–µ –∑–∞–¥–∞–Ω–∏–µ –ø–æ –¥–∏–ø–ª–æ–º', 'task'],\n",
       " ['–∫–∞–∫ –∑–∞–ø–æ–ª–Ω—è—Ç—å –∑–∞–¥–∞–Ω–∏–µ –∫ –≤–∫—Ä', 'task'],\n",
       " ['–∫–∞–∫ –∑–∞–ø–æ–ª–Ω—è—Ç—å –∑–∞–¥–∞–Ω–∏–µ –∫ –¥–∏–ø–ª–æ–º', 'task'],\n",
       " ['–∫–∞–∫ –∑–∞–ø–æ–ª–Ω—è—Ç—å –¥–∏–ø–ª–æ–º–Ω—ã–π –∑–∞–¥–∞–Ω–∏–µ', 'task'],\n",
       " ['–∫–∞–∫ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –∑–∞–ø–æ–ª–Ω—è—Ç—å –∑–∞–¥–∞–Ω–∏–µ –∫ –≤–∫—Ä', 'task'],\n",
       " ['–∫–∞–∫ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –∑–∞–ø–æ–ª–Ω—è—Ç—å –∑–∞–¥–∞–Ω–∏–µ –∫ –¥–∏–ø–ª–æ–º', 'task'],\n",
       " ['–∫–∞–∫ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –∑–∞–ø–æ–ª–Ω—è—Ç—å –¥–∏–ø–ª–æ–º–Ω—ã–π –∑–∞–¥–∞–Ω–∏–µ', 'task'],\n",
       " ['—á–µ–π –ø–æ–¥–ø–∏—Å—å –Ω—É–∂–Ω—ã–π –Ω–∞ –∑–∞–¥–∞–Ω–∏–µ –∫ –≤–∫—Ä', 'task'],\n",
       " ['—á–µ–π –ø–æ–¥–ø–∏—Å—å –Ω—É–∂–Ω—ã–π –Ω–∞ –∑–∞–¥–∞–Ω–∏–µ –∫ –¥–∏–ø–ª–æ–º', 'task'],\n",
       " ['—á–µ–π –ø–æ–¥–ø–∏—Å—å –Ω—É–∂–Ω—ã–π –Ω–∞ –¥–∏–ø–ª–æ–º–Ω—ã–π –∑–∞–¥–∞–Ω–∏–µ', 'task'],\n",
       " ['–∫—Ç–æ –¥–æ–ª–∂–Ω—ã–π —Ä–∞—Å–ø–∏—Å—ã–≤–∞—Ç—å—Å—è –Ω–∞ –∑–∞–¥–∞–Ω–∏–µ –∫ –≤–∫—Ä', 'task'],\n",
       " ['–∫—Ç–æ –¥–æ–ª–∂–Ω—ã–π —Ä–∞—Å–ø–∏—Å—ã–≤–∞—Ç—å—Å—è –Ω–∞ –∑–∞–¥–∞–Ω–∏–µ –∫ –¥–∏–ø–ª–æ–º', 'task'],\n",
       " ['–∫—Ç–æ –¥–æ–ª–∂–Ω—ã–π —Ä–∞—Å–ø–∏—Å—ã–≤–∞—Ç—å—Å—è –Ω–∞ –¥–∏–ø–ª–æ–º–Ω—ã–π –∑–∞–¥–∞–Ω–∏–µ', 'task'],\n",
       " ['–∫–∞–∫ –¥–æ–ª–∂–Ω—ã–π –±—ã—Ç—å –æ—Ñ–æ—Ä–º–ª—è—Ç—å –∞–Ω–Ω–æ—Ç–∞—Ü–∏—è', 'annotation'],\n",
       " ['–∫–∞–∫ –∑–∞–ø–æ–ª–Ω—è—Ç—å –∞–Ω–Ω–æ—Ç–∞—Ü–∏—è', 'annotation'],\n",
       " ['–∫–∞–∫–æ–π —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–µ –∫ –∞–Ω–Ω–æ—Ç–∞—Ü–∏—è', 'annotation'],\n",
       " ['–∫–∞–∫–æ–π —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–µ –∫ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏–µ –∞–Ω–Ω–æ—Ç–∞—Ü–∏—è', 'annotation'],\n",
       " ['–∫–∞–∫ –æ—Ñ–æ—Ä–º–ª—è—Ç—å –∞–Ω–Ω–æ—Ç–∞—Ü–∏—è', 'annotation'],\n",
       " ['–∫–∞–∫ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –æ—Ñ–æ—Ä–º–ª—è—Ç—å –∞–Ω–Ω–æ—Ç–∞—Ü–∏—è', 'annotation'],\n",
       " ['–∫—Ç–æ –¥–æ–ª–∂–Ω—ã–π —Ä–∞—Å–ø–∏—Å—ã–≤–∞—Ç—å—Å—è –Ω–∞ –∞–Ω–Ω–æ—Ç–∞—Ü–∏—è', 'annotation'],\n",
       " ['—á–µ–π –ø–æ–¥–ø–∏—Å—å –¥–æ–ª–∂–Ω—ã–π –±—ã—Ç—å –Ω–∞ –∞–Ω–Ω–æ—Ç–∞—Ü–∏—è', 'annotation'],\n",
       " ['–∫–∞–∫–æ–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –∞–Ω–Ω–æ—Ç–∞—Ü–∏—è', 'annotation'],\n",
       " ['–∫–∞–∫ –æ—Ñ–æ—Ä–º–ª—è—Ç—å —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ', 'content'],\n",
       " ['–∫–∞–∫ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –æ—Ñ–æ—Ä–º–ª—è—Ç—å —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ', 'content'],\n",
       " ['–∫–∞–∫ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –æ—Ñ–æ—Ä–º–ª—è—Ç—å —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ', 'content'],\n",
       " ['–∫–∞–∫ –∑–∞–ø–æ–ª–Ω—è—Ç—å —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ', 'content'],\n",
       " ['–∫–∞–∫–æ–π —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–µ –∫ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ', 'content'],\n",
       " ['–∫—Ç–æ –¥–æ–ª–∂–Ω—ã–π –ø–æ–¥–ø–∏—Å—ã–≤–∞—Ç—å —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ', 'content'],\n",
       " ['—á–µ–π –ø–æ–¥–ø–∏—Å—å –¥–æ–ª–∂–Ω—ã–π –±—ã—Ç—å –≤ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ', 'content'],\n",
       " ['–∫–∞–∫–æ–π —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–µ –∫ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ', 'content'],\n",
       " ['–∫–∞–∫–æ–π —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–µ –∫ –ø–æ—è—Å–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∑–∞–ø–∏—Å–∫–∞', 'work'],\n",
       " ['–∫–∞–∫–æ–π —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–µ –∫ –ø–∑', 'work'],\n",
       " ['–∫–∞–∫ –¥–æ–ª–∂–Ω—ã–π –±—ã—Ç—å –æ—Ñ–æ—Ä–º–ª—è—Ç—å –ø–æ—è—Å–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∑–∞–ø–∏—Å–∫–∞', 'work'],\n",
       " ['–∫–∞–∫ –¥–æ–ª–∂–Ω—ã–π –±—ã—Ç—å –æ—Ñ–æ—Ä–º–ª—è—Ç—å –ø–∑', 'work'],\n",
       " ['–∫–∞–∫ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –æ—Ñ–æ—Ä–º–ª—è—Ç—å –ø–æ—è—Å–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∑–∞–ø–∏—Å–∫–∞', 'work'],\n",
       " ['–∫–∞–∫ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –æ—Ñ–æ—Ä–º–ª—è—Ç—å –ø–∑', 'work'],\n",
       " ['–∫–∞–∫ –æ—Ñ–æ—Ä–º–ª—è—Ç—å –ø–æ—è—Å–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∑–∞–ø–∏—Å–∫–∞', 'work'],\n",
       " ['–∫–∞–∫ –æ—Ñ–æ—Ä–º–ª—è—Ç—å –ø–∑', 'work'],\n",
       " ['–∫–∞–∫–æ–π —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–µ –∫ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏–µ –ø–æ—è—Å–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∑–∞–ø–∏—Å–∫–∞', 'work'],\n",
       " ['–∫–∞–∫–æ–π —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–µ –∫ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏–µ –ø–∑', 'work'],\n",
       " ['–∫–∞–∫ –∑–∞–ø–æ–ª–Ω—è—Ç—å –ø–æ—è—Å–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∑–∞–ø–∏—Å–∫–∞', 'work'],\n",
       " ['–∫–∞–∫ –∑–∞–ø–æ–ª–Ω—è—Ç—å –ø–∑', 'work'],\n",
       " ['–∫–∞–∫ –∑–∞–ø–æ–ª–Ω—è—Ç—å —Å–ø–∏—Å–æ–∫ –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–∞', 'literature'],\n",
       " ['–∫–∞–∫ –Ω—É–∂–Ω–æ –æ—Ñ–æ—Ä–º–ª—è—Ç—å —Å–ø–∏—Å–æ–∫ –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–∞', 'literature'],\n",
       " ['–∫–∞–∫ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –æ—Ñ–æ—Ä–º–ª—è—Ç—å —Å–ø–∏—Å–æ–∫ –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–∞', 'literature'],\n",
       " ['–∫–∞–∫ –æ—Ñ–æ—Ä–º–ª—è—Ç—å —Å–ø–∏—Å–æ–∫ –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–∞', 'literature'],\n",
       " ['–∫–∞–∫–æ–π —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–µ –∫ —Å–ø–∏—Å–æ–∫ –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–∞', 'literature'],\n",
       " ['–∫–∞–∫–æ–π —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–µ –∫ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏–µ —Å–ø–∏—Å–æ–∫ –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–∞', 'literature'],\n",
       " ['–∫–∞–∫ –¥–æ–ª–∂–Ω—ã–π –±—ã—Ç—å –æ—Ñ–æ—Ä–º–ª—è—Ç—å —Å–ø–∏—Å–æ–∫ –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–∞ ', 'literature'],\n",
       " ['–∫–∞–∫ –Ω—É–∂–Ω–æ –æ—Ñ–æ—Ä–º–ª—è—Ç—å –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ', 'supplement'],\n",
       " ['–∫–∞–∫ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –æ—Ñ–æ—Ä–º–ª—è—Ç—å –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ', 'supplement'],\n",
       " ['–∫–∞–∫ –æ—Ñ–æ—Ä–º–ª—è—Ç—å –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ', 'supplement'],\n",
       " ['–∫–∞–∫–æ–π —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–µ –∫ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ', 'supplement'],\n",
       " ['–∫–∞–∫–æ–π —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–µ –∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ', 'supplement'],\n",
       " ['–∫–∞–∫ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –æ—Ñ–æ—Ä–º–ª—è—Ç—å –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ ', 'supplement'],\n",
       " ['–∫–∞–∫ –∑–∞–ø–æ–ª–Ω—è—Ç—å –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ', 'supplement'],\n",
       " ['—á—Ç–æ –¥–µ–ª–∞—Ç—å –ø–æ—Å–ª–µ –Ω–æ—Ä–º–∫–æ–Ω—Ç—Ä–æ–ª—å', 'after'],\n",
       " ['—á—Ç–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —Å–¥–µ–ª–∞—Ç—å –ø–æ—Å–ª–µ –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏–µ –Ω–æ—Ä–º–∫–æ–Ω—Ç—Ä–æ–ª—å', 'after'],\n",
       " ['—á—Ç–æ –Ω—É–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å –ø–æ—Å–ª–µ –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏–µ –Ω–æ—Ä–º–∫–æ–Ω—Ç—Ä–æ–ª—å', 'after'],\n",
       " ['—á—Ç–æ –¥–µ–ª–∞—Ç—å –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω—ã–π –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏–µ –Ω–æ—Ä–º–∫–æ–Ω—Ç—Ä–æ–ª—å', 'after'],\n",
       " ['—á—Ç–æ –¥–µ–ª–∞—Ç—å –ø–æ—Å–ª–µ –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏–µ –Ω–æ—Ä–º–∫–æ–Ω—Ç—Ä–æ–ª—å', 'after'],\n",
       " ['–∫—Ç–æ –ø–æ–¥–ø–∏—Å—ã–≤–∞—Ç—å –¥–∏—Å–∫', 'CD-ROM'],\n",
       " ['–∫–∞–∫ –ø–æ–¥–ø–∏—Å—ã–≤–∞—Ç—å –∫–æ–º–ø–∞–∫—Ç–¥–∏—Å–∫', 'CD-ROM'],\n",
       " ['—Å–∫–æ–ª—å–∫–æ –¥–∏—Å–∫ –Ω—É–∂–Ω–æ', 'CD-ROM'],\n",
       " ['—Å–∫–æ–ª—å–∫–æ –∫–æ–º–ø–∞–∫—Ç–¥–∏—Å–∫ –Ω—É–∂–Ω–æ', 'CD-ROM'],\n",
       " ['–∫—Ç–æ –¥–æ–ª–∂–Ω—ã–π –ø–æ–¥–ø–∏—Å—ã–≤–∞—Ç—å –¥–∏—Å–∫', 'CD-ROM'],\n",
       " ['–∫—Ç–æ –¥–æ–ª–∂–Ω—ã–π –ø–æ–¥–ø–∏—Å—ã–≤–∞—Ç—å –∫–æ–º–ø–∞–∫—Ç–¥–∏—Å–∫', 'CD-ROM'],\n",
       " ['—á–µ–π –ø–æ–¥–ø–∏—Å—å –Ω—É–∂–Ω—ã–π –Ω–∞ –¥–∏—Å–∫', 'CD-ROM'],\n",
       " ['—á–µ–π –ø–æ–¥–ø–∏—Å—å –Ω—É–∂–Ω—ã–π –Ω–∞ –∫–æ–º–ø–∞–∫—Ç–¥–∏—Å–∫', 'CD-ROM'],\n",
       " ['—á—Ç–æ –∑–∞–ø–∏—Å—ã–≤–∞—Ç—å –Ω–∞ –ø–µ—Ä–≤—ã–π –¥–∏—Å–∫', 'CD-ROM'],\n",
       " ['—á—Ç–æ –∑–∞–ø–∏—Å—ã–≤–∞—Ç—å –Ω–∞ –ø–µ—Ä–≤—ã–π –∫–æ–º–ø–∞–∫—Ç–¥–∏—Å–∫', 'CD-ROM'],\n",
       " ['—á—Ç–æ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –Ω–∞ –ø–µ—Ä–≤—ã–π –¥–∏—Å–∫', 'CD-ROM'],\n",
       " ['—á—Ç–æ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –Ω–∞ –ø–µ—Ä–≤—ã–π –∫–æ–º–ø–∞–∫—Ç–¥–∏—Å–∫', 'CD-ROM'],\n",
       " ['—á—Ç–æ –∑–∞–ø–∏—Å—ã–≤–∞—Ç—å –Ω–∞ –≤—Ç–æ—Ä–æ–π –¥–∏—Å–∫', 'CD-ROM'],\n",
       " ['—á—Ç–æ –∑–∞–ø–∏—Å—ã–≤–∞—Ç—å –Ω–∞ –≤—Ç–æ—Ä–æ–π –∫–æ–º–ø–∞–∫—Ç–¥–∏—Å–∫', 'CD-ROM'],\n",
       " ['—á—Ç–æ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –Ω–∞ –≤—Ç–æ—Ä–æ–π –¥–∏—Å–∫', 'CD-ROM'],\n",
       " ['—á—Ç–æ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –Ω–∞ –≤—Ç–æ—Ä–æ–π –∫–æ–º–ø–∞–∫—Ç–¥–∏—Å–∫', 'CD-ROM'],\n",
       " ['–∫–∞–∫–æ–π –¥–∏—Å–∫ –¥–æ–ª–∂–Ω—ã–π –±—ã—Ç—å', 'CD-ROM'],\n",
       " ['cd –∏–ª–∏ dvd –¥–∏—Å–∫', 'CD-ROM'],\n",
       " ['—á—Ç–æ —Ç–∞–∫–æ–π –≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–π —á–∞—Å—Ç—å', 'graphic part'],\n",
       " ['—á—Ç–æ —Ç–∞–∫–æ–π —Ä–∞–∑–¥–∞—Ç–æ—á–Ω—ã–π –º–∞—Ç–µ—Ä–∏–∞–ª', 'graphic part'],\n",
       " ['—á—Ç–æ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—Ç—å –∏–∑ —Å–µ–±—è –≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–π —á–∞—Å—Ç—å', 'graphic part'],\n",
       " ['—á—Ç–æ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—Ç—å –∏–∑ —Å–µ–±—è —Ä–∞–∑–¥–∞—Ç–æ—á–Ω—ã–π –º–∞—Ç–µ—Ä–∏–∞–ª', 'graphic part'],\n",
       " ['–∫–∞–∫ –æ—Ñ–æ—Ä–º–ª—è—Ç—å –≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–π –º–∞—Ç–µ—Ä–∏–∞–ª', 'graphic part'],\n",
       " ['–∫–∞–∫ –æ—Ñ–æ—Ä–º–ª—è—Ç—å —Ä–∞–∑–¥–∞—Ç–æ—á–Ω—ã–π –º–∞—Ç–µ—Ä–∏–∞–ª', 'graphic part'],\n",
       " ['–∫—Ç–æ –¥–æ–ª–∂–Ω—ã–π –ø–æ–¥–ø–∏—Å—ã–≤–∞—Ç—å –≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–π —á–∞—Å—Ç—å', 'graphic part'],\n",
       " ['—á–µ–π –ø–æ–¥–ø–∏—Å—å –¥–æ–ª–∂–Ω—ã–π –±—ã—Ç—å –Ω–∞ –≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–π —á–∞—Å—Ç—å', 'graphic part'],\n",
       " ['–∫—Ç–æ –¥–æ–ª–∂–Ω—ã–π –ø–æ–¥–ø–∏—Å—ã–≤–∞—Ç—å —Ä–∞–∑–¥–∞—Ç–æ—á–Ω—ã–π –º–∞—Ç–µ—Ä–∏–∞–ª', 'graphic part'],\n",
       " ['—á–µ–π –ø–æ–¥–ø–∏—Å—å –¥–æ–ª–∂–Ω—ã–π –±—ã—Ç—å –Ω–∞ —Ä–∞–∑–¥–∞—Ç–æ—á–Ω—ã–π –º–∞—Ç–µ—Ä–∏–∞–ª', 'graphic part'],\n",
       " ['–∏–∑ —á—Ç–æ —Å–æ—Å—Ç–æ—è—Ç—å –≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–π —á–∞—Å—Ç—å', 'graphic part'],\n",
       " ['–∏–∑ —á—Ç–æ —Å–æ—Å—Ç–æ—è—Ç—å —Ä–∞–∑–¥–∞—Ç–æ—á–Ω—ã–π –º–∞—Ç–µ—Ä–∏–∞–ª', 'graphic part'],\n",
       " ['–∫–∞–∫–æ–π —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–µ –∫ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–π —á–∞—Å—Ç—å', 'graphic part'],\n",
       " ['–∫–∞–∫–æ–π —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–µ –∫ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏–µ —Ä–∞–∑–¥–∞—Ç–æ—á–Ω—ã–π –º–∞—Ç–µ—Ä–∏–∞–ª ', 'graphic part'],\n",
       " ['—á—Ç–æ —Ç–∞–∫–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∞–Ω—Ç–∏–ø–ª–∞–≥–∏–∞—Ç', 'anti-plagiarism'],\n",
       " ['—á—Ç–æ —Ç–∞–∫–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø–ª–∞–≥–∏–∞—Ç', 'anti-plagiarism'],\n",
       " ['—á—Ç–æ –∏–∑ —Å–µ–±—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—Ç—å –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø–ª–∞–≥–∏–∞—Ç', 'anti-plagiarism'],\n",
       " ['—á—Ç–æ –∏–∑ —Å–µ–±—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—Ç—å –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∞–Ω—Ç–∏–ø–ª–∞–≥–∏–∞—Ç', 'anti-plagiarism'],\n",
       " ['–≤ —á—Ç–æ –∑–∞–∫–ª—é—á–∞—Ç—å—Å—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø–ª–∞–≥–∏–∞—Ç', 'anti-plagiarism'],\n",
       " ['–≤ —á—Ç–æ –∑–∞–∫–ª—é—á–∞—Ç—å—Å—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∞–Ω—Ç–∏–ø–ª–∞–≥–∏–∞—Ç', 'anti-plagiarism'],\n",
       " ['–∫–∞–∫–æ–π –ø—Ä–æ—Ü–µ–Ω—Ç —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç—å —Ç–µ–∫—Å—Ç', 'anti-plagiarism'],\n",
       " ['–∫—Ç–æ –≥–æ—Ç–æ–≤–∏—Ç—å —Å–ø—Ä–∞–≤–∫–∞ –æ–± –∞–Ω—Ç–∏–ø–ª–∞–≥–∏–∞—Ç', 'anti-plagiarism'],\n",
       " ['–∫—Ç–æ –æ—Ñ–æ—Ä–º–ª—è—Ç—å —Å–ø—Ä–∞–≤–∫–∞ –æ–± –∞–Ω—Ç–∏–ø–ª–∞–≥–∏–∞—Ç', 'anti-plagiarism'],\n",
       " ['–∫—Ç–æ –ø–æ–¥–ø–∏—Å—ã–≤–∞—Ç—å —Å–ø—Ä–∞–≤–∫–∞ –æ–± –∞–Ω—Ç–∏–ø–ª–∞–≥–∏–∞—Ç', 'anti-plagiarism'],\n",
       " ['–∫—Ç–æ —Ä–∞—Å–ø–∏—Å—ã–≤–∞—Ç—å—Å—è –Ω–∞ —Å–ø—Ä–∞–≤–∫–∞ –æ–± –∞–Ω—Ç–∏–ø–ª–∞–≥–∏–∞—Ç', 'anti-plagiarism'],\n",
       " ['—á–µ–π –ø–æ–¥–ø–∏—Å—å –Ω—É–∂–Ω—ã–π –¥–ª—è —Å–ø—Ä–∞–≤–∫–∞ –æ–± –∞–Ω—Ç–∏–ø–ª–∞–≥–∏–∞—Ç', 'anti-plagiarism'],\n",
       " ['–∫—Ç–æ –ø–æ–¥–ø–∏—Å—ã–≤–∞—Ç—å —Ä–µ—Ü–µ–Ω–∑–∏—è', 'review'],\n",
       " ['—á–µ–π –ø–æ–¥–ø–∏—Å—å –Ω—É–∂–Ω—ã–π –¥–ª—è —Ä–µ—Ü–µ–Ω–∑–∏—è', 'review'],\n",
       " ['–Ω—É–∂–Ω—ã–π –ª–∏ —Ä–µ—Ü–µ–Ω–∑–∏—è –¥–ª—è –±–∞–∫–∞–ª–∞–≤—Ä', 'review'],\n",
       " ['–¥–ª—è –±–∞–∫–∞–ª–∞–≤—Ä–∏–∞—Ç –Ω—É–∂–Ω—ã–π —Ä–µ—Ü–µ–Ω–∑–∏—è', 'review'],\n",
       " ['–±–∞–∫–∞–ª–∞–≤—Ä –Ω—É–∂–Ω—ã–π —Ä–µ—Ü–µ–Ω–∑–∏—è', 'review'],\n",
       " ['–Ω—É–∂–Ω—ã–π –ª–∏ –ø–µ—á–∞—Ç—å –ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏–µ –¥–ª—è —Ä–µ—Ü–µ–Ω–∑–∏—è', 'review'],\n",
       " ['–∫–∞–∫ —Å–æ—Å—Ç–∞–≤–ª—è—Ç—å —Ä–µ—Ü–µ–Ω–∑–∏—è', 'review'],\n",
       " ['–∫–∞–∫ –∑–∞–ø–æ–ª–Ω—è—Ç—å —Ä–µ—Ü–µ–Ω–∑–∏—è', 'review'],\n",
       " ['–ø—Ä–∏–≤–µ—Ç–∏–∫', 'greeting'],\n",
       " ['–ø—Ä–∏–≤–µ—Ç–∏–∫', 'greeting'],\n",
       " ['–¥–æ–±—Ä—ã–π –≤—Ä–µ–º—è —Å—É—Ç–∫–∏', 'greeting'],\n",
       " ['–ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–æ–≤–∞—Ç—å', 'greeting'],\n",
       " ['–∑–¥—Ä–∞–≤—Å—Ç–≤–æ–≤–∞—Ç—å', 'greeting'],\n",
       " ['—Ä–∞–¥ –≤—ã —Å–ª—ã—à–∞—Ç—å', 'greeting'],\n",
       " ['–¥–æ–±—Ä—ã–π —É—Ç—Ä–æ', 'greeting'],\n",
       " ['–¥–æ–±—Ä—ã–π –¥–µ–Ω—å', 'greeting'],\n",
       " ['–¥–æ–±—Ä—ã–π –≤–µ—á–µ—Ä', 'greeting'],\n",
       " ['–ø—Ä–∏–≤–µ—Ç', 'greeting'],\n",
       " ['–∑–¥—Ä–∞–≤—Å—Ç–≤–æ–≤–∞—Ç—å', 'greeting'],\n",
       " ['–±–æ—Ç', 'greeting'],\n",
       " ['—Å–ø–∞—Å–∏–±–æ', 'gratitude'],\n",
       " ['—Å–ø–∞—Å–∏–±–æ –±–æ–ª—å—à–æ–π', 'gratitude'],\n",
       " ['–±–ª–∞–≥–æ–¥–∞—Ä–∏—Ç—å', 'gratitude'],\n",
       " ['–≤–µ—Å—å–º–∞ –ø—Ä–∏–∑–Ω–∞—Ç–µ–ª—å–Ω—ã–π', 'gratitude'],\n",
       " ['–ø—Ä–µ–º–Ω–æ–≥–æ –±–ª–∞–≥–æ–¥–∞—Ä–Ω—ã–π', 'gratitude'],\n",
       " ['—Å–ø–∞—Å–∏–±–æ –≤—ã—Ä—É—á–∞—Ç—å', 'gratitude'],\n",
       " ['—Å–ø–∞—Å–∏–±–æ –∑–∞ –ø–æ–º–æ—â—å', 'gratitude'],\n",
       " ['–±–ª–∞–≥–æ–¥–∞—Ä—Å—Ç–≤–æ–≤–∞—Ç—å', 'gratitude'],\n",
       " ['–ø–æ–∫–∞', 'goodbye'],\n",
       " ['–ø–æ–∫–∞', 'goodbye'],\n",
       " ['–ø–æ–∫–∞–ø–æ–∫–∞', 'goodbye'],\n",
       " ['–ø—Ä–æ—â–∞–π', 'goodbye'],\n",
       " ['—Ö–æ—Ä–æ—à–∏–π –¥–µ–Ω—å', 'goodbye'],\n",
       " ['–¥–æ –≤—Å—Ç—Ä–µ—á–∞', 'goodbye'],\n",
       " ['–¥–æ —Å–≤–∏–¥–∞–Ω–∏–µ', 'goodbye'],\n",
       " ['–¥–æ –Ω–æ–≤—ã–π –≤—Å—Ç—Ä–µ—á–∞', 'goodbye'],\n",
       " ['—Å—á–∞—Å—Ç–ª–∏–≤–æ', 'goodbye'],\n",
       " ['–¥–æ —Å–∫–æ—Ä—ã–π –≤—Å—Ç—Ä–µ—á–∞', 'goodbye'],\n",
       " ['–¥–æ –∑–∞–≤—Ç—Ä–∞', 'goodbye'],\n",
       " ['–≤–µ—Å—å –¥–æ–±—Ä—ã–π', 'goodbye'],\n",
       " ['–≤–µ—Å—å —Ö–æ—Ä–æ—à–∏–π', 'goodbye'],\n",
       " ['–ø—Ä–æ—â–∞—Ç—å', 'goodbye'],\n",
       " ['–∫—Ç–æ –≥–æ—Ç–æ–≤–∏—Ç—å –æ—Ç–∑—ã–≤ —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å', 'feedback'],\n",
       " ['–∫—Ç–æ —Å–æ—Å—Ç–∞–≤–ª—è—Ç—å –æ—Ç–∑—ã–≤ —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å', 'feedback'],\n",
       " ['–∫—Ç–æ –æ—Ç–≤–µ—á–∞—Ç—å –∑–∞ –æ—Ç–∑—ã–≤ —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å', 'feedback'],\n",
       " ['–∫–∞–∫ –Ω–∞–ø–∏—Å–∞—Ç—å –æ—Ç–∑—ã–≤ —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å', 'feedback'],\n",
       " ['–∫–∞–∫ —Å–æ—Å—Ç–∞–≤–ª—è—Ç—å –æ—Ç–∑—ã–≤ —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å', 'feedback'],\n",
       " ['–∫–∞–∫ –∑–∞–ø–æ–ª–Ω—è—Ç—å –æ—Ç–∑—ã–≤ —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å', 'feedback'],\n",
       " ['–∫–æ–≥–¥–∞ –±—ã—Ç—å –Ω–æ—Ä–º–æ–∫–æ–Ω—Ç—Ä–æ–ª—å', 'time&place'],\n",
       " ['–∫–æ–≥–¥–∞ –±—ã—Ç—å –ø—Ä–æ—Ö–æ–¥–∏—Ç—å –Ω–æ—Ä–º–æ–∫–æ–Ω—Ç—Ä–æ–ª—å', 'time&place'],\n",
       " ['–≥–¥–µ –±—ã—Ç—å –Ω–æ—Ä–º–æ–∫–æ–Ω—Ç—Ä–æ–ª—å', 'time&place'],\n",
       " ['–≥–¥–µ –±—ã—Ç—å –ø—Ä–æ—Ö–æ–¥–∏—Ç—å –Ω–æ—Ä–º–æ–∫–æ–Ω—Ç—Ä–æ–ª—å', 'time&place'],\n",
       " ['–≤ –∫–∞–∫–æ–π –∫–æ—Ä–ø—É—Å –±—ã—Ç—å –Ω–æ—Ä–º–æ–∫–æ–Ω—Ç—Ä–æ–ª—å', 'time&place'],\n",
       " ['–≤ –∫–∞–∫–æ–π –∫–æ—Ä–ø—É—Å –±—ã—Ç—å –ø—Ä–æ—Ö–æ–¥–∏—Ç—å –Ω–æ—Ä–º–æ–∫–æ–Ω—Ç—Ä–æ–ª—å', 'time&place'],\n",
       " ['–≤ –∫–∞–∫–æ–π –∞—É–¥–∏—Ç–æ—Ä–∏—è –±—ã—Ç—å –Ω–æ—Ä–º–æ–∫–æ–Ω—Ç—Ä–æ–ª—å', 'time&place'],\n",
       " ['–≤ –∫–∞–∫–æ–π –∞—É–¥–∏—Ç–æ—Ä–∏—è –±—ã—Ç—å –ø—Ä–æ—Ö–æ–¥–∏—Ç—å –Ω–æ—Ä–º–æ–∫–æ–Ω—Ç—Ä–æ–ª—å', 'time&place'],\n",
       " ['–≤ –∫–∞–∫–æ–π –≤—Ä–µ–º—è –±—ã—Ç—å –Ω–æ—Ä–º–æ–∫–æ–Ω—Ç—Ä–æ–ª—å', 'time&place'],\n",
       " ['–≤ –∫–∞–∫–æ–π –≤—Ä–µ–º—è –±—ã—Ç—å –ø—Ä–æ—Ö–æ–¥–∏—Ç—å –Ω–æ—Ä–º–æ–∫–æ–Ω—Ç—Ä–æ–ª—å', 'time&place']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "mFd7xtTEhvnP",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count examples:216\n",
      "Count intents:18\n"
     ]
    }
   ],
   "source": [
    "# –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ –Ω–∞ –ø—Ä–∏–º–µ—Ä—ã –∏ –º–µ—Ç–∫–∏ –∫–ª–∞—Å—Å–æ–≤\n",
    "X_text = [x for x, y in dataset]\n",
    "y = [y for x, y in dataset]\n",
    "print('Count examples:' + str(len(X_text)))\n",
    "print('Count intents:' + str(len(set(y))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "m1mohgfVhvnQ"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "from sklearn.naive_bayes import GaussianNB  \n",
    "from sklearn.tree import DecisionTreeClassifier  \n",
    "from sklearn.svm import LinearSVC "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è\n",
    "vectorizer = CountVectorizer(analyzer='char_wb', ngram_range=(2,3), max_df=0.85)\n",
    "data = vectorizer.fit_transform(X_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "0q2sz-8NF4hV"
   },
   "outputs": [],
   "source": [
    "# –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫—É\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, y, test_size=0.33, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –û—Ü–µ–Ω–∫–∞ —Ä–∞–±–æ—Ç—ã –º–æ–¥–µ–ª–∏ –Ω–∞ –∫—Ä–æ—Å—Å –≤–∞–ª–∏–¥–∞—Ü–∏–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "KadLvVAIGJh8"
   },
   "outputs": [],
   "source": [
    " # –†–∞–∑–±–∏–µ–Ω–∏–µ –Ω–∞ 5 —Ñ–æ–ª–¥–æ–≤\n",
    "skf = KFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "IxdHUjN5GUzn"
   },
   "outputs": [],
   "source": [
    "# –§—É–Ω–∫—Ü–∏—è –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è –∏ –ø–æ–¥—Å—á—ë—Ç–∞ –¥–æ–ª–∏ –≤–µ—Ä–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤ \n",
    "def learn_score(classifier, parameters):\n",
    "  clf = GridSearchCV(classifier, param_grid=parameters, cv=skf, scoring='accuracy')\n",
    "  clf.fit(X_train.toarray(), y_train)\n",
    "  # –°—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ\n",
    "  mean_values = clf.cv_results_['mean_test_score']\n",
    "  # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ\n",
    "  std_values = clf.cv_results_['std_test_score']\n",
    "  print('Accuracy on train data:')\n",
    "  for i in range(len(mean_values)):\n",
    "    print(str(clf.cv_results_['params'][i]) + ': ' + str(round(mean_values[i], 3)) + ' +/- ' + str(round(std_values[i], 3)))\n",
    "  print('\\n' + 'Best parameters: ' + str(clf.best_params_))\n",
    "  print('\\nDetailed classification report (test data):')\n",
    "  print(classification_report(y_test, clf.predict(X_test.toarray())))\n",
    "  print('\\n\\n')\n",
    "  return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "esItLEUwLtXE"
   },
   "outputs": [],
   "source": [
    "# –°–ª–æ–≤–∞—Ä—å —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞\n",
    "classifiers = {'KNN': {'n_neighbors': [2,3,4,5,6,7,8,9,10]},                                                                                 # –ú–µ—Ç–æ–¥ k –±–ª–∏–∂–∞–π—à–∏—Ö —Å–æ—Å–µ–¥–µ–π\n",
    "               'DTC': {'criterion': ['gini', 'entropy'], 'max_depth': [2,3,4,5,6,7,8,9,10]},                                                 # –î–µ—Ä–µ–≤–æ —Ä–µ—à–µ–Ω–∏–π\n",
    "               'NB': {'priors': [None]},                                                                                                     # –ù–∞–∏–≤–Ω—ã–π –ë–∞–π–µ—Å\n",
    "               'LR': {'penalty': ['l1', 'l2', 'elasticnet', 'none'], 'class_weight': ['balanced', None], 'max_iter': [100]},    # –õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è\n",
    "               'SVM': {'C': [1.0, 1.25, 1.5, 1.75, 2.0], 'class_weight': ['balanced', None], 'max_iter': [100]}}                # –ú–µ—Ç–æ–¥ –æ–ø–æ—Ä–Ω—ã—Ö –≤–µ–∫—Ç–æ—Ä–æ–≤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "5mcjaF6SMBVD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train data:\n",
      "{'n_neighbors': 2}: 0.68 +/- 0.06\n",
      "{'n_neighbors': 3}: 0.652 +/- 0.083\n",
      "{'n_neighbors': 4}: 0.667 +/- 0.074\n",
      "{'n_neighbors': 5}: 0.646 +/- 0.054\n",
      "{'n_neighbors': 6}: 0.638 +/- 0.074\n",
      "{'n_neighbors': 7}: 0.646 +/- 0.077\n",
      "{'n_neighbors': 8}: 0.618 +/- 0.088\n",
      "{'n_neighbors': 9}: 0.633 +/- 0.072\n",
      "{'n_neighbors': 10}: 0.577 +/- 0.049\n",
      "\n",
      "Best parameters: {'n_neighbors': 2}\n",
      "\n",
      "Detailed classification report (test data):\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         CD-ROM       0.56      0.83      0.67         6\n",
      "          after       1.00      1.00      1.00         2\n",
      "     annotation       0.67      0.67      0.67         3\n",
      "anti-plagiarism       1.00      0.75      0.86         4\n",
      "        content       1.00      0.67      0.80         3\n",
      "       feedback       1.00      1.00      1.00         2\n",
      "        goodbye       0.44      1.00      0.62         4\n",
      "   graphic part       1.00      1.00      1.00         5\n",
      "      gratitude       1.00      0.33      0.50         3\n",
      "       greeting       0.50      0.25      0.33         4\n",
      "     literature       1.00      0.50      0.67         2\n",
      "   normocontrol       1.00      1.00      1.00        10\n",
      "         review       1.00      0.67      0.80         3\n",
      "     supplement       0.50      1.00      0.67         2\n",
      "           task       1.00      1.00      1.00         7\n",
      "     time&place       1.00      1.00      1.00         3\n",
      "          title       1.00      0.80      0.89         5\n",
      "           work       1.00      0.75      0.86         4\n",
      "\n",
      "       accuracy                           0.82        72\n",
      "      macro avg       0.87      0.79      0.80        72\n",
      "   weighted avg       0.88      0.82      0.82        72\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=KNeighborsClassifier(),\n",
       "             param_grid={'n_neighbors': [2, 3, 4, 5, 6, 7, 8, 9, 10]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_score(KNeighborsClassifier(), classifiers['KNN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train data:\n",
      "{'criterion': 'gini', 'max_depth': 2}: 0.286 +/- 0.105\n",
      "{'criterion': 'gini', 'max_depth': 3}: 0.376 +/- 0.112\n",
      "{'criterion': 'gini', 'max_depth': 4}: 0.466 +/- 0.088\n",
      "{'criterion': 'gini', 'max_depth': 5}: 0.501 +/- 0.085\n",
      "{'criterion': 'gini', 'max_depth': 6}: 0.501 +/- 0.096\n",
      "{'criterion': 'gini', 'max_depth': 7}: 0.535 +/- 0.092\n",
      "{'criterion': 'gini', 'max_depth': 8}: 0.584 +/- 0.121\n",
      "{'criterion': 'gini', 'max_depth': 9}: 0.66 +/- 0.052\n",
      "{'criterion': 'gini', 'max_depth': 10}: 0.695 +/- 0.057\n",
      "{'criterion': 'entropy', 'max_depth': 2}: 0.341 +/- 0.07\n",
      "{'criterion': 'entropy', 'max_depth': 3}: 0.389 +/- 0.096\n",
      "{'criterion': 'entropy', 'max_depth': 4}: 0.521 +/- 0.076\n",
      "{'criterion': 'entropy', 'max_depth': 5}: 0.577 +/- 0.113\n",
      "{'criterion': 'entropy', 'max_depth': 6}: 0.701 +/- 0.06\n",
      "{'criterion': 'entropy', 'max_depth': 7}: 0.729 +/- 0.046\n",
      "{'criterion': 'entropy', 'max_depth': 8}: 0.743 +/- 0.085\n",
      "{'criterion': 'entropy', 'max_depth': 9}: 0.729 +/- 0.059\n",
      "{'criterion': 'entropy', 'max_depth': 10}: 0.744 +/- 0.103\n",
      "\n",
      "Best parameters: {'criterion': 'entropy', 'max_depth': 10}\n",
      "\n",
      "Detailed classification report (test data):\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         CD-ROM       1.00      1.00      1.00         6\n",
      "          after       1.00      1.00      1.00         2\n",
      "     annotation       1.00      0.67      0.80         3\n",
      "anti-plagiarism       0.50      0.50      0.50         4\n",
      "        content       0.60      1.00      0.75         3\n",
      "       feedback       0.67      1.00      0.80         2\n",
      "        goodbye       1.00      0.75      0.86         4\n",
      "   graphic part       0.60      0.60      0.60         5\n",
      "      gratitude       1.00      0.33      0.50         3\n",
      "       greeting       0.50      0.50      0.50         4\n",
      "     literature       0.00      0.00      0.00         2\n",
      "   normocontrol       1.00      0.90      0.95        10\n",
      "         review       1.00      0.33      0.50         3\n",
      "     supplement       0.50      1.00      0.67         2\n",
      "           task       0.88      1.00      0.93         7\n",
      "     time&place       0.75      1.00      0.86         3\n",
      "          title       0.83      1.00      0.91         5\n",
      "           work       0.80      1.00      0.89         4\n",
      "\n",
      "       accuracy                           0.79        72\n",
      "      macro avg       0.76      0.75      0.72        72\n",
      "   weighted avg       0.80      0.79      0.77        72\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=DecisionTreeClassifier(),\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_score(DecisionTreeClassifier(), classifiers['DTC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train data:\n",
      "{'priors': None}: 0.73 +/- 0.066\n",
      "\n",
      "Best parameters: {'priors': None}\n",
      "\n",
      "Detailed classification report (test data):\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         CD-ROM       1.00      1.00      1.00         6\n",
      "          after       1.00      0.50      0.67         2\n",
      "     annotation       1.00      0.67      0.80         3\n",
      "anti-plagiarism       1.00      1.00      1.00         4\n",
      "        content       1.00      1.00      1.00         3\n",
      "       feedback       1.00      1.00      1.00         2\n",
      "        goodbye       1.00      1.00      1.00         4\n",
      "   graphic part       0.71      1.00      0.83         5\n",
      "      gratitude       1.00      1.00      1.00         3\n",
      "       greeting       1.00      1.00      1.00         4\n",
      "     literature       0.00      0.00      0.00         2\n",
      "   normocontrol       0.91      1.00      0.95        10\n",
      "         review       1.00      1.00      1.00         3\n",
      "     supplement       1.00      1.00      1.00         2\n",
      "           task       0.88      1.00      0.93         7\n",
      "     time&place       1.00      1.00      1.00         3\n",
      "          title       1.00      1.00      1.00         5\n",
      "           work       1.00      1.00      1.00         4\n",
      "\n",
      "       accuracy                           0.94        72\n",
      "      macro avg       0.92      0.90      0.90        72\n",
      "   weighted avg       0.93      0.94      0.93        72\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=GaussianNB(), param_grid={'priors': [None]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_score(GaussianNB(), classifiers['NB'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train data:\n",
      "{'class_weight': 'balanced', 'max_iter': 100, 'penalty': 'l1'}: nan +/- nan\n",
      "{'class_weight': 'balanced', 'max_iter': 100, 'penalty': 'l2'}: 0.903 +/- 0.025\n",
      "{'class_weight': 'balanced', 'max_iter': 100, 'penalty': 'elasticnet'}: nan +/- nan\n",
      "{'class_weight': 'balanced', 'max_iter': 100, 'penalty': 'none'}: 0.903 +/- 0.025\n",
      "{'class_weight': None, 'max_iter': 100, 'penalty': 'l1'}: nan +/- nan\n",
      "{'class_weight': None, 'max_iter': 100, 'penalty': 'l2'}: 0.875 +/- 0.028\n",
      "{'class_weight': None, 'max_iter': 100, 'penalty': 'elasticnet'}: nan +/- nan\n",
      "{'class_weight': None, 'max_iter': 100, 'penalty': 'none'}: 0.882 +/- 0.018\n",
      "\n",
      "Best parameters: {'class_weight': 'balanced', 'max_iter': 100, 'penalty': 'l2'}\n",
      "\n",
      "Detailed classification report (test data):\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         CD-ROM       1.00      0.83      0.91         6\n",
      "          after       1.00      1.00      1.00         2\n",
      "     annotation       1.00      1.00      1.00         3\n",
      "anti-plagiarism       1.00      1.00      1.00         4\n",
      "        content       1.00      1.00      1.00         3\n",
      "       feedback       1.00      1.00      1.00         2\n",
      "        goodbye       0.57      1.00      0.73         4\n",
      "   graphic part       1.00      1.00      1.00         5\n",
      "      gratitude       1.00      0.67      0.80         3\n",
      "       greeting       0.67      0.50      0.57         4\n",
      "     literature       1.00      1.00      1.00         2\n",
      "   normocontrol       1.00      0.90      0.95        10\n",
      "         review       1.00      1.00      1.00         3\n",
      "     supplement       1.00      1.00      1.00         2\n",
      "           task       1.00      1.00      1.00         7\n",
      "     time&place       0.75      1.00      0.86         3\n",
      "          title       1.00      1.00      1.00         5\n",
      "           work       1.00      1.00      1.00         4\n",
      "\n",
      "       accuracy                           0.93        72\n",
      "      macro avg       0.94      0.94      0.93        72\n",
      "   weighted avg       0.95      0.93      0.93        72\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=LogisticRegression(),\n",
       "             param_grid={'class_weight': ['balanced', None], 'max_iter': [100],\n",
       "                         'penalty': ['l1', 'l2', 'elasticnet', 'none']},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_score(LogisticRegression(), classifiers['LR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train data:\n",
      "{'C': 1.0, 'class_weight': 'balanced', 'max_iter': 100}: 0.91 +/- 0.035\n",
      "{'C': 1.0, 'class_weight': None, 'max_iter': 100}: 0.91 +/- 0.035\n",
      "{'C': 1.25, 'class_weight': 'balanced', 'max_iter': 100}: 0.91 +/- 0.035\n",
      "{'C': 1.25, 'class_weight': None, 'max_iter': 100}: 0.91 +/- 0.035\n",
      "{'C': 1.5, 'class_weight': 'balanced', 'max_iter': 100}: 0.91 +/- 0.035\n",
      "{'C': 1.5, 'class_weight': None, 'max_iter': 100}: 0.91 +/- 0.035\n",
      "{'C': 1.75, 'class_weight': 'balanced', 'max_iter': 100}: 0.91 +/- 0.035\n",
      "{'C': 1.75, 'class_weight': None, 'max_iter': 100}: 0.91 +/- 0.035\n",
      "{'C': 2.0, 'class_weight': 'balanced', 'max_iter': 100}: 0.91 +/- 0.035\n",
      "{'C': 2.0, 'class_weight': None, 'max_iter': 100}: 0.91 +/- 0.035\n",
      "\n",
      "Best parameters: {'C': 1.0, 'class_weight': 'balanced', 'max_iter': 100}\n",
      "\n",
      "Detailed classification report (test data):\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         CD-ROM       1.00      1.00      1.00         6\n",
      "          after       1.00      1.00      1.00         2\n",
      "     annotation       1.00      1.00      1.00         3\n",
      "anti-plagiarism       1.00      1.00      1.00         4\n",
      "        content       1.00      1.00      1.00         3\n",
      "       feedback       1.00      1.00      1.00         2\n",
      "        goodbye       1.00      0.75      0.86         4\n",
      "   graphic part       1.00      1.00      1.00         5\n",
      "      gratitude       1.00      0.67      0.80         3\n",
      "       greeting       0.67      1.00      0.80         4\n",
      "     literature       1.00      1.00      1.00         2\n",
      "   normocontrol       1.00      1.00      1.00        10\n",
      "         review       1.00      1.00      1.00         3\n",
      "     supplement       1.00      1.00      1.00         2\n",
      "           task       1.00      1.00      1.00         7\n",
      "     time&place       1.00      1.00      1.00         3\n",
      "          title       1.00      1.00      1.00         5\n",
      "           work       1.00      1.00      1.00         4\n",
      "\n",
      "       accuracy                           0.97        72\n",
      "      macro avg       0.98      0.97      0.97        72\n",
      "   weighted avg       0.98      0.97      0.97        72\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=LinearSVC(),\n",
       "             param_grid={'C': [1.0, 1.25, 1.5, 1.75, 2.0],\n",
       "                         'class_weight': ['balanced', None],\n",
       "                         'max_iter': [100]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_score(LinearSVC(), classifiers['SVM'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –¥—Ä—É–≥–æ–≥–æ –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ç–æ—Ä–∞ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è\n",
    "vectorizer = TfidfVectorizer(analyzer='char_wb', ngram_range=(2,3), max_df=0.85, sublinear_tf=True)\n",
    "data = vectorizer.fit_transform(X_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫—É\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, y, test_size=0.33, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train data:\n",
      "{'n_neighbors': 2}: 0.729 +/- 0.061\n",
      "{'n_neighbors': 3}: 0.764 +/- 0.044\n",
      "{'n_neighbors': 4}: 0.771 +/- 0.027\n",
      "{'n_neighbors': 5}: 0.736 +/- 0.054\n",
      "{'n_neighbors': 6}: 0.742 +/- 0.064\n",
      "{'n_neighbors': 7}: 0.715 +/- 0.064\n",
      "{'n_neighbors': 8}: 0.708 +/- 0.059\n",
      "{'n_neighbors': 9}: 0.687 +/- 0.075\n",
      "{'n_neighbors': 10}: 0.687 +/- 0.102\n",
      "\n",
      "Best parameters: {'n_neighbors': 4}\n",
      "\n",
      "Detailed classification report (test data):\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         CD-ROM       0.67      1.00      0.80         6\n",
      "          after       1.00      1.00      1.00         2\n",
      "     annotation       1.00      1.00      1.00         3\n",
      "anti-plagiarism       1.00      1.00      1.00         4\n",
      "        content       0.67      0.67      0.67         3\n",
      "       feedback       1.00      1.00      1.00         2\n",
      "        goodbye       0.50      0.25      0.33         4\n",
      "   graphic part       0.83      1.00      0.91         5\n",
      "      gratitude       1.00      0.67      0.80         3\n",
      "       greeting       1.00      0.25      0.40         4\n",
      "     literature       1.00      1.00      1.00         2\n",
      "   normocontrol       0.71      1.00      0.83        10\n",
      "         review       1.00      0.67      0.80         3\n",
      "     supplement       1.00      1.00      1.00         2\n",
      "           task       1.00      1.00      1.00         7\n",
      "     time&place       0.00      0.00      0.00         3\n",
      "          title       1.00      1.00      1.00         5\n",
      "           work       0.80      1.00      0.89         4\n",
      "\n",
      "       accuracy                           0.83        72\n",
      "      macro avg       0.84      0.81      0.80        72\n",
      "   weighted avg       0.83      0.83      0.81        72\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=KNeighborsClassifier(),\n",
       "             param_grid={'n_neighbors': [2, 3, 4, 5, 6, 7, 8, 9, 10]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_score(KNeighborsClassifier(), classifiers['KNN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train data:\n",
      "{'criterion': 'gini', 'max_depth': 2}: 0.326 +/- 0.064\n",
      "{'criterion': 'gini', 'max_depth': 3}: 0.341 +/- 0.053\n",
      "{'criterion': 'gini', 'max_depth': 4}: 0.41 +/- 0.062\n",
      "{'criterion': 'gini', 'max_depth': 5}: 0.438 +/- 0.053\n",
      "{'criterion': 'gini', 'max_depth': 6}: 0.459 +/- 0.043\n",
      "{'criterion': 'gini', 'max_depth': 7}: 0.486 +/- 0.073\n",
      "{'criterion': 'gini', 'max_depth': 8}: 0.5 +/- 0.064\n",
      "{'criterion': 'gini', 'max_depth': 9}: 0.535 +/- 0.034\n",
      "{'criterion': 'gini', 'max_depth': 10}: 0.59 +/- 0.069\n",
      "{'criterion': 'entropy', 'max_depth': 2}: 0.326 +/- 0.082\n",
      "{'criterion': 'entropy', 'max_depth': 3}: 0.41 +/- 0.08\n",
      "{'criterion': 'entropy', 'max_depth': 4}: 0.465 +/- 0.082\n",
      "{'criterion': 'entropy', 'max_depth': 5}: 0.513 +/- 0.113\n",
      "{'criterion': 'entropy', 'max_depth': 6}: 0.596 +/- 0.135\n",
      "{'criterion': 'entropy', 'max_depth': 7}: 0.618 +/- 0.064\n",
      "{'criterion': 'entropy', 'max_depth': 8}: 0.666 +/- 0.061\n",
      "{'criterion': 'entropy', 'max_depth': 9}: 0.638 +/- 0.07\n",
      "{'criterion': 'entropy', 'max_depth': 10}: 0.638 +/- 0.059\n",
      "\n",
      "Best parameters: {'criterion': 'entropy', 'max_depth': 8}\n",
      "\n",
      "Detailed classification report (test data):\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         CD-ROM       1.00      1.00      1.00         6\n",
      "          after       1.00      1.00      1.00         2\n",
      "     annotation       0.67      0.67      0.67         3\n",
      "anti-plagiarism       1.00      1.00      1.00         4\n",
      "        content       1.00      1.00      1.00         3\n",
      "       feedback       1.00      1.00      1.00         2\n",
      "        goodbye       0.50      0.75      0.60         4\n",
      "   graphic part       0.67      0.40      0.50         5\n",
      "      gratitude       0.25      0.67      0.36         3\n",
      "       greeting       0.00      0.00      0.00         4\n",
      "     literature       1.00      0.50      0.67         2\n",
      "   normocontrol       1.00      1.00      1.00        10\n",
      "         review       1.00      0.33      0.50         3\n",
      "     supplement       1.00      1.00      1.00         2\n",
      "           task       1.00      1.00      1.00         7\n",
      "     time&place       1.00      1.00      1.00         3\n",
      "          title       0.67      0.80      0.73         5\n",
      "           work       1.00      1.00      1.00         4\n",
      "\n",
      "       accuracy                           0.81        72\n",
      "      macro avg       0.82      0.78      0.78        72\n",
      "   weighted avg       0.83      0.81      0.80        72\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=DecisionTreeClassifier(),\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_score(DecisionTreeClassifier(), classifiers['DTC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train data:\n",
      "{'priors': None}: 0.784 +/- 0.056\n",
      "\n",
      "Best parameters: {'priors': None}\n",
      "\n",
      "Detailed classification report (test data):\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         CD-ROM       1.00      1.00      1.00         6\n",
      "          after       1.00      1.00      1.00         2\n",
      "     annotation       1.00      0.33      0.50         3\n",
      "anti-plagiarism       1.00      0.75      0.86         4\n",
      "        content       1.00      0.67      0.80         3\n",
      "       feedback       1.00      1.00      1.00         2\n",
      "        goodbye       0.75      0.75      0.75         4\n",
      "   graphic part       0.71      1.00      0.83         5\n",
      "      gratitude       1.00      0.67      0.80         3\n",
      "       greeting       0.67      0.50      0.57         4\n",
      "     literature       1.00      1.00      1.00         2\n",
      "   normocontrol       1.00      1.00      1.00        10\n",
      "         review       1.00      1.00      1.00         3\n",
      "     supplement       0.67      1.00      0.80         2\n",
      "           task       0.88      1.00      0.93         7\n",
      "     time&place       0.75      1.00      0.86         3\n",
      "          title       1.00      1.00      1.00         5\n",
      "           work       0.80      1.00      0.89         4\n",
      "\n",
      "       accuracy                           0.89        72\n",
      "      macro avg       0.90      0.87      0.87        72\n",
      "   weighted avg       0.90      0.89      0.88        72\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=GaussianNB(), param_grid={'priors': [None]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_score(GaussianNB(), classifiers['NB'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train data:\n",
      "{'class_weight': 'balanced', 'max_iter': 100, 'penalty': 'l1'}: nan +/- nan\n",
      "{'class_weight': 'balanced', 'max_iter': 100, 'penalty': 'l2'}: 0.896 +/- 0.038\n",
      "{'class_weight': 'balanced', 'max_iter': 100, 'penalty': 'elasticnet'}: nan +/- nan\n",
      "{'class_weight': 'balanced', 'max_iter': 100, 'penalty': 'none'}: 0.902 +/- 0.048\n",
      "{'class_weight': None, 'max_iter': 100, 'penalty': 'l1'}: nan +/- nan\n",
      "{'class_weight': None, 'max_iter': 100, 'penalty': 'l2'}: 0.742 +/- 0.108\n",
      "{'class_weight': None, 'max_iter': 100, 'penalty': 'elasticnet'}: nan +/- nan\n",
      "{'class_weight': None, 'max_iter': 100, 'penalty': 'none'}: 0.895 +/- 0.051\n",
      "\n",
      "Best parameters: {'class_weight': 'balanced', 'max_iter': 100, 'penalty': 'none'}\n",
      "\n",
      "Detailed classification report (test data):\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         CD-ROM       1.00      1.00      1.00         6\n",
      "          after       1.00      1.00      1.00         2\n",
      "     annotation       1.00      1.00      1.00         3\n",
      "anti-plagiarism       1.00      1.00      1.00         4\n",
      "        content       1.00      1.00      1.00         3\n",
      "       feedback       1.00      1.00      1.00         2\n",
      "        goodbye       0.75      0.75      0.75         4\n",
      "   graphic part       1.00      1.00      1.00         5\n",
      "      gratitude       1.00      0.67      0.80         3\n",
      "       greeting       0.60      0.75      0.67         4\n",
      "     literature       1.00      1.00      1.00         2\n",
      "   normocontrol       1.00      1.00      1.00        10\n",
      "         review       1.00      1.00      1.00         3\n",
      "     supplement       1.00      1.00      1.00         2\n",
      "           task       1.00      1.00      1.00         7\n",
      "     time&place       1.00      1.00      1.00         3\n",
      "          title       1.00      1.00      1.00         5\n",
      "           work       1.00      1.00      1.00         4\n",
      "\n",
      "       accuracy                           0.96        72\n",
      "      macro avg       0.96      0.95      0.96        72\n",
      "   weighted avg       0.96      0.96      0.96        72\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=LogisticRegression(),\n",
       "             param_grid={'class_weight': ['balanced', None], 'max_iter': [100],\n",
       "                         'penalty': ['l1', 'l2', 'elasticnet', 'none']},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_score(LogisticRegression(), classifiers['LR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train data:\n",
      "{'C': 1.0, 'class_weight': 'balanced', 'max_iter': 100}: 0.902 +/- 0.052\n",
      "{'C': 1.0, 'class_weight': None, 'max_iter': 100}: 0.916 +/- 0.048\n",
      "{'C': 1.25, 'class_weight': 'balanced', 'max_iter': 100}: 0.896 +/- 0.039\n",
      "{'C': 1.25, 'class_weight': None, 'max_iter': 100}: 0.916 +/- 0.048\n",
      "{'C': 1.5, 'class_weight': 'balanced', 'max_iter': 100}: 0.896 +/- 0.039\n",
      "{'C': 1.5, 'class_weight': None, 'max_iter': 100}: 0.916 +/- 0.048\n",
      "{'C': 1.75, 'class_weight': 'balanced', 'max_iter': 100}: 0.896 +/- 0.039\n",
      "{'C': 1.75, 'class_weight': None, 'max_iter': 100}: 0.916 +/- 0.048\n",
      "{'C': 2.0, 'class_weight': 'balanced', 'max_iter': 100}: 0.902 +/- 0.041\n",
      "{'C': 2.0, 'class_weight': None, 'max_iter': 100}: 0.916 +/- 0.048\n",
      "\n",
      "Best parameters: {'C': 1.0, 'class_weight': None, 'max_iter': 100}\n",
      "\n",
      "Detailed classification report (test data):\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         CD-ROM       1.00      1.00      1.00         6\n",
      "          after       1.00      1.00      1.00         2\n",
      "     annotation       1.00      1.00      1.00         3\n",
      "anti-plagiarism       1.00      1.00      1.00         4\n",
      "        content       1.00      1.00      1.00         3\n",
      "       feedback       1.00      1.00      1.00         2\n",
      "        goodbye       0.75      0.75      0.75         4\n",
      "   graphic part       1.00      1.00      1.00         5\n",
      "      gratitude       1.00      0.67      0.80         3\n",
      "       greeting       0.50      0.50      0.50         4\n",
      "     literature       1.00      1.00      1.00         2\n",
      "   normocontrol       1.00      1.00      1.00        10\n",
      "         review       1.00      1.00      1.00         3\n",
      "     supplement       1.00      1.00      1.00         2\n",
      "           task       1.00      1.00      1.00         7\n",
      "     time&place       0.75      1.00      0.86         3\n",
      "          title       1.00      1.00      1.00         5\n",
      "           work       1.00      1.00      1.00         4\n",
      "\n",
      "       accuracy                           0.94        72\n",
      "      macro avg       0.94      0.94      0.94        72\n",
      "   weighted avg       0.95      0.94      0.94        72\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=LinearSVC(),\n",
       "             param_grid={'C': [1.0, 1.25, 1.5, 1.75, 2.0],\n",
       "                         'class_weight': ['balanced', None],\n",
       "                         'max_iter': [100]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_score(LinearSVC(), classifiers['SVM'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –¥—Ä—É–≥–æ–≥–æ –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ç–æ—Ä–∞ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è\n",
    "vectorizer = HashingVectorizer(analyzer='char_wb', ngram_range=(2,3))\n",
    "data = vectorizer.fit_transform(X_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫—É\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, y, test_size=0.33, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train data:\n",
      "{'n_neighbors': 2}: 0.652 +/- 0.088\n",
      "{'n_neighbors': 3}: 0.618 +/- 0.034\n",
      "{'n_neighbors': 4}: 0.624 +/- 0.073\n",
      "{'n_neighbors': 5}: 0.611 +/- 0.055\n",
      "{'n_neighbors': 6}: 0.562 +/- 0.069\n",
      "{'n_neighbors': 7}: 0.583 +/- 0.044\n",
      "{'n_neighbors': 8}: 0.576 +/- 0.055\n",
      "{'n_neighbors': 9}: 0.548 +/- 0.07\n",
      "{'n_neighbors': 10}: 0.541 +/- 0.067\n",
      "\n",
      "Best parameters: {'n_neighbors': 2}\n",
      "\n",
      "Detailed classification report (test data):\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         CD-ROM       0.67      1.00      0.80         6\n",
      "          after       1.00      1.00      1.00         2\n",
      "     annotation       0.33      0.33      0.33         3\n",
      "anti-plagiarism       1.00      0.75      0.86         4\n",
      "        content       1.00      0.67      0.80         3\n",
      "       feedback       0.67      1.00      0.80         2\n",
      "        goodbye       0.57      0.80      0.67         5\n",
      "   graphic part       0.60      0.60      0.60         5\n",
      "      gratitude       1.00      1.00      1.00         3\n",
      "       greeting       1.00      0.25      0.40         4\n",
      "     literature       1.00      1.00      1.00         2\n",
      "   normocontrol       0.83      1.00      0.91        10\n",
      "         review       1.00      0.67      0.80         3\n",
      "     supplement       0.67      1.00      0.80         2\n",
      "           task       1.00      1.00      1.00         7\n",
      "     time&place       0.50      0.33      0.40         3\n",
      "          title       0.75      0.75      0.75         4\n",
      "           work       1.00      0.50      0.67         4\n",
      "\n",
      "       accuracy                           0.78        72\n",
      "      macro avg       0.81      0.76      0.75        72\n",
      "   weighted avg       0.81      0.78      0.77        72\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=KNeighborsClassifier(),\n",
       "             param_grid={'n_neighbors': [2, 3, 4, 5, 6, 7, 8, 9, 10]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_score(KNeighborsClassifier(), classifiers['KNN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train data:\n",
      "{'criterion': 'gini', 'max_depth': 2}: 0.222 +/- 0.035\n",
      "{'criterion': 'gini', 'max_depth': 3}: 0.291 +/- 0.079\n",
      "{'criterion': 'gini', 'max_depth': 4}: 0.388 +/- 0.101\n",
      "{'criterion': 'gini', 'max_depth': 5}: 0.416 +/- 0.093\n",
      "{'criterion': 'gini', 'max_depth': 6}: 0.437 +/- 0.091\n",
      "{'criterion': 'gini', 'max_depth': 7}: 0.472 +/- 0.097\n",
      "{'criterion': 'gini', 'max_depth': 8}: 0.514 +/- 0.056\n",
      "{'criterion': 'gini', 'max_depth': 9}: 0.625 +/- 0.077\n",
      "{'criterion': 'gini', 'max_depth': 10}: 0.659 +/- 0.105\n",
      "{'criterion': 'entropy', 'max_depth': 2}: 0.347 +/- 0.104\n",
      "{'criterion': 'entropy', 'max_depth': 3}: 0.423 +/- 0.09\n",
      "{'criterion': 'entropy', 'max_depth': 4}: 0.548 +/- 0.112\n",
      "{'criterion': 'entropy', 'max_depth': 5}: 0.659 +/- 0.09\n",
      "{'criterion': 'entropy', 'max_depth': 6}: 0.715 +/- 0.101\n",
      "{'criterion': 'entropy', 'max_depth': 7}: 0.708 +/- 0.097\n",
      "{'criterion': 'entropy', 'max_depth': 8}: 0.729 +/- 0.134\n",
      "{'criterion': 'entropy', 'max_depth': 9}: 0.736 +/- 0.118\n",
      "{'criterion': 'entropy', 'max_depth': 10}: 0.695 +/- 0.075\n",
      "\n",
      "Best parameters: {'criterion': 'entropy', 'max_depth': 9}\n",
      "\n",
      "Detailed classification report (test data):\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         CD-ROM       1.00      1.00      1.00         6\n",
      "          after       0.00      0.00      0.00         2\n",
      "     annotation       1.00      1.00      1.00         3\n",
      "anti-plagiarism       1.00      0.75      0.86         4\n",
      "        content       1.00      1.00      1.00         3\n",
      "       feedback       1.00      1.00      1.00         2\n",
      "        goodbye       1.00      0.60      0.75         5\n",
      "   graphic part       1.00      1.00      1.00         5\n",
      "      gratitude       0.33      0.33      0.33         3\n",
      "       greeting       0.40      0.50      0.44         4\n",
      "     literature       1.00      1.00      1.00         2\n",
      "   normocontrol       0.75      0.90      0.82        10\n",
      "         review       0.50      1.00      0.67         3\n",
      "     supplement       1.00      0.50      0.67         2\n",
      "           task       1.00      1.00      1.00         7\n",
      "     time&place       0.67      0.67      0.67         3\n",
      "          title       1.00      1.00      1.00         4\n",
      "           work       1.00      1.00      1.00         4\n",
      "\n",
      "       accuracy                           0.83        72\n",
      "      macro avg       0.81      0.79      0.79        72\n",
      "   weighted avg       0.84      0.83      0.83        72\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=DecisionTreeClassifier(),\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_score(DecisionTreeClassifier(), classifiers['DTC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train data:\n",
      "{'priors': None}: 0.742 +/- 0.086\n",
      "\n",
      "Best parameters: {'priors': None}\n",
      "\n",
      "Detailed classification report (test data):\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         CD-ROM       1.00      1.00      1.00         6\n",
      "          after       1.00      0.50      0.67         2\n",
      "     annotation       0.50      0.33      0.40         3\n",
      "anti-plagiarism       1.00      0.75      0.86         4\n",
      "        content       1.00      0.67      0.80         3\n",
      "       feedback       1.00      1.00      1.00         2\n",
      "        goodbye       1.00      0.80      0.89         5\n",
      "   graphic part       0.71      1.00      0.83         5\n",
      "      gratitude       1.00      1.00      1.00         3\n",
      "       greeting       1.00      1.00      1.00         4\n",
      "     literature       1.00      1.00      1.00         2\n",
      "   normocontrol       0.83      1.00      0.91        10\n",
      "         review       0.67      0.67      0.67         3\n",
      "     supplement       1.00      0.50      0.67         2\n",
      "           task       0.78      1.00      0.88         7\n",
      "     time&place       1.00      1.00      1.00         3\n",
      "          title       1.00      1.00      1.00         4\n",
      "           work       1.00      1.00      1.00         4\n",
      "\n",
      "       accuracy                           0.89        72\n",
      "      macro avg       0.92      0.85      0.86        72\n",
      "   weighted avg       0.90      0.89      0.88        72\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=GaussianNB(), param_grid={'priors': [None]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_score(GaussianNB(), classifiers['NB'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    }
   ],
   "source": [
    "learn_score(LogisticRegression(), classifiers['LR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train data:\n",
      "{'C': 1.0, 'class_weight': 'balanced', 'max_iter': 100}: 0.917 +/- 0.042\n",
      "{'C': 1.0, 'class_weight': None, 'max_iter': 100}: 0.882 +/- 0.056\n",
      "{'C': 1.25, 'class_weight': 'balanced', 'max_iter': 100}: 0.91 +/- 0.035\n",
      "{'C': 1.25, 'class_weight': None, 'max_iter': 100}: 0.889 +/- 0.046\n",
      "{'C': 1.5, 'class_weight': 'balanced', 'max_iter': 100}: 0.91 +/- 0.035\n",
      "{'C': 1.5, 'class_weight': None, 'max_iter': 100}: 0.889 +/- 0.046\n",
      "{'C': 1.75, 'class_weight': 'balanced', 'max_iter': 100}: 0.91 +/- 0.035\n",
      "{'C': 1.75, 'class_weight': None, 'max_iter': 100}: 0.889 +/- 0.046\n",
      "{'C': 2.0, 'class_weight': 'balanced', 'max_iter': 100}: 0.91 +/- 0.035\n",
      "{'C': 2.0, 'class_weight': None, 'max_iter': 100}: 0.91 +/- 0.047\n",
      "\n",
      "Best parameters: {'C': 1.0, 'class_weight': 'balanced', 'max_iter': 100}\n",
      "\n",
      "Detailed classification report (test data):\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         CD-ROM       1.00      1.00      1.00         6\n",
      "          after       1.00      1.00      1.00         2\n",
      "     annotation       1.00      1.00      1.00         3\n",
      "anti-plagiarism       1.00      0.75      0.86         4\n",
      "        content       1.00      1.00      1.00         3\n",
      "       feedback       1.00      1.00      1.00         2\n",
      "        goodbye       1.00      0.80      0.89         5\n",
      "   graphic part       1.00      1.00      1.00         5\n",
      "      gratitude       1.00      0.67      0.80         3\n",
      "       greeting       0.67      1.00      0.80         4\n",
      "     literature       1.00      1.00      1.00         2\n",
      "   normocontrol       1.00      1.00      1.00        10\n",
      "         review       1.00      1.00      1.00         3\n",
      "     supplement       1.00      1.00      1.00         2\n",
      "           task       1.00      1.00      1.00         7\n",
      "     time&place       1.00      1.00      1.00         3\n",
      "          title       0.80      1.00      0.89         4\n",
      "           work       1.00      1.00      1.00         4\n",
      "\n",
      "       accuracy                           0.96        72\n",
      "      macro avg       0.97      0.96      0.96        72\n",
      "   weighted avg       0.97      0.96      0.96        72\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=LinearSVC(),\n",
       "             param_grid={'C': [1.0, 1.25, 1.5, 1.75, 2.0],\n",
       "                         'class_weight': ['balanced', None],\n",
       "                         'max_iter': [100]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_score(LinearSVC(), classifiers['SVM'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –í—ã–±–æ—Ä –Ω–∞–∏–ª—É—á—à–µ–≥–æ –Ω–∞–±–æ—Ä–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫—Ä–æ—Å—Å –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –∏ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞ –≤—Å–µ–º –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –°–±–æ—Ä –º–µ—Ç—Ä–∏–∫ –Ω–∞ –æ–±—É—á–µ–Ω–∏–∏ –∏ —Ç–µ—Å—Ç–µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è\n",
    "vectorizer = CountVectorizer(analyzer='char_wb', ngram_range=(2,3), max_df=0.85)\n",
    "data = vectorizer.fit_transform(X_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫—É\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, y, test_size=0.33, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(class_weight='balanced', max_iter=100)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å –ª—É—á—à–∏–º–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –Ω–∞ –≤—Å–µ–º –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è\n",
    "model = LinearSVC(C=1.0, class_weight='balanced', max_iter=100)\n",
    "model.fit(X_train.toarray(), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Detailed classification report (test data):\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         CD-ROM       1.00      1.00      1.00         6\n",
      "          after       1.00      1.00      1.00         2\n",
      "     annotation       1.00      1.00      1.00         3\n",
      "anti-plagiarism       1.00      1.00      1.00         4\n",
      "        content       1.00      1.00      1.00         3\n",
      "       feedback       1.00      1.00      1.00         2\n",
      "        goodbye       1.00      0.75      0.86         4\n",
      "   graphic part       1.00      1.00      1.00         5\n",
      "      gratitude       0.75      1.00      0.86         3\n",
      "       greeting       0.75      0.75      0.75         4\n",
      "     literature       1.00      1.00      1.00         2\n",
      "   normocontrol       1.00      1.00      1.00        10\n",
      "         review       1.00      1.00      1.00         3\n",
      "     supplement       1.00      1.00      1.00         2\n",
      "           task       1.00      1.00      1.00         7\n",
      "     time&place       1.00      1.00      1.00         3\n",
      "          title       1.00      1.00      1.00         5\n",
      "           work       1.00      1.00      1.00         4\n",
      "\n",
      "       accuracy                           0.97        72\n",
      "      macro avg       0.97      0.97      0.97        72\n",
      "   weighted avg       0.98      0.97      0.97        72\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\nDetailed classification report (test data):')\n",
    "print(classification_report(y_test, model.predict(X_test.toarray())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On train set: 1.0\n",
      "On test set: 0.9722222222222222\n"
     ]
    }
   ],
   "source": [
    "print(\"On train set: {}\".format(accuracy_score(y_train, model.predict(X_train))))\n",
    "print(\"On test set: {}\".format(accuracy_score(y_test, model.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Neural_network_test (1).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
